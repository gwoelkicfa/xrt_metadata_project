{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To use these functions, run all of the cells up to the master cell, then call any desired functions \n",
    "# using the master cell.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from operator import itemgetter\n",
    "import gc\n",
    "from os import walk\n",
    "from os import path\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.colors import ColorConverter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "from StringIO import StringIO\n",
    "import requests\n",
    "from scipy.interpolate import spline\n",
    "import pyfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getHinodeFlareCat(time1,time2,fm=False,fmn=False,fme=False,nm=False):\n",
    "    '''Return a pandas dataframe containing the Hinode Flare Catalog data from between time1 and time2.\n",
    "    \n",
    "    Arguments:\n",
    "    time1 -- The initial time boundary (datetime object)\n",
    "    time2 -- The final time boundary (datetime object)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    fm -- Focus Mode only (default False)\n",
    "    fmn -- Normal Focus Mode (not eclipse season) only (default False)\n",
    "    fme -- Eclipse season Focus Mode only (default False)\n",
    "    nm -- Normal mode only (default False)'''\n",
    "    \n",
    "    time1 = time1.strftime('%Y/%m/%d %H:%M')\n",
    "    time2 = time2.strftime('%Y/%m/%d %H:%M')\n",
    "    \n",
    "    # Read csv file and store data in a csv file\n",
    "    f = urllib2.urlopen('http://st4a.stelab.nagoya-u.ac.jp/hinode_flare/csv/all_event.csv')\n",
    "    strio = StringIO(requests.get('http://st4a.stelab.nagoya-u.ac.jp/hinode_flare/csv/all_event.csv').content)\n",
    "    df = pd.read_csv(strio,error_bad_lines=False)\n",
    "    \n",
    "    df.columns = ['num','t_start','t_end','t_peak','loc','class','x','y','SOT','SP','XRT','EIS','RHESSI','SUZAKU/WAM','NoRH']\n",
    "    \n",
    "    # Focus mode time ranges\n",
    "    if fm or nm:\n",
    "        tFocus = [('2014/01/11 09:00','2014/02/08 09:00'),('2014/05/31 09:00','2014/06/28 09:00'),\n",
    "                  ('2014/12/16 09:00','2015/01/05 09:00'),('2015/01/12 09:00','2015/02/03 09:00'),\n",
    "                  ('2015/05/25 09:00','2015/06/16 09:00'),('2015/06/22 09:00','2015/07/14 09:00'),\n",
    "                  ('2015/07/20 09:00','2015/08/10 09:00')]\n",
    "    \n",
    "    if fme:\n",
    "        tFocus = [('2014/05/31 09:00','2014/06/28 09:00'),('2015/05/25 09:00','2015/06/16 09:00'),\n",
    "                  ('2015/06/22 09:00','2015/07/14 09:00'),('2015/07/20 09:00','2015/08/10 09:00')]\n",
    "    \n",
    "    if fmn:\n",
    "        tFocus = [('2014/01/11 09:00','2014/02/08 09:00'),('2014/12/16 09:00','2015/01/05 09:00'),\n",
    "                  ('2015/01/12 09:00','2015/02/03 09:00')]\n",
    "\n",
    "    \n",
    "    # Used to for focus mode related filtering\n",
    "    drop = []\n",
    "    if fm or fmn or fme or nm:\n",
    "        for i in range(len(df)):\n",
    "            t = df['t_start'][i]\n",
    "            for focusMode in tFocus:\n",
    "                if (t > focusMode[0] and t < focusMode[1]) is not (fm or fmn or fme): \n",
    "                    if i not in drop:\n",
    "                        drop.append(i)\n",
    "                elif fm or fmn or fme:\n",
    "                    if i in drop:\n",
    "                        drop.remove(i)\n",
    "                    break;\n",
    "    \n",
    "    # Some of these flares can break the plots\n",
    "    for i,flare in df.iterrows():\n",
    "        if abs(flare['y']) > 900:\n",
    "            if i not in drop:\n",
    "                drop.append(i)\n",
    "    \n",
    "    # Filter out flares outside of time1 to time2 period\n",
    "    return df.drop(df.index[[drop]]).query('t_start > @time1 and t_start < @time2');\n",
    "\n",
    "def getXrtFlareCat(time1,time2,fm=False,fmn=False,fme=False,nm=False):\n",
    "    '''Return a pandas dataframe of the XRT Flare Catalog data between time1 and time2.\n",
    "    Arguments are datetime objects. time1 must be prior to time2\n",
    "    \n",
    "    Arguments:\n",
    "    time1 -- The initial time boundary (datetime object)\n",
    "    time2 -- The final time boundary (datetime object)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    fm -- Focus Mode only (default False)\n",
    "    fmn -- Normal Focus Mode (not eclipse season) only (default False)\n",
    "    fme -- Eclipse season Focus Mode only (default False)\n",
    "    nm -- Normal mode only (default False)'''\n",
    "    \n",
    "    time1 = time1.strftime('%Y/%m/%d %H:%M')\n",
    "    time2 = time2.strftime('%Y/%m/%d %H:%M')\n",
    "    \n",
    "    # An automatically generated csv is not yet available online\n",
    "    # Reads csv file made by Nicole Schanche and stores data in a pandas dataframe\n",
    "    df = pd.read_csv('XRT_flarecat(1).csv',error_bad_lines=False)\n",
    "    df.columns = ['id','flarecat','t_start','t_end','t_peak','loc','class','x','y','SOT','XRT','EIS','RHESSI','NORH',\n",
    "                  'combos','movies','response','pre_flare','obs_note','region','HEK']\n",
    "    \n",
    "    # Focus mode time ranges\n",
    "    if fm or nm:\n",
    "        tFocus = [('2014/01/11 09:00','2014/02/08 09:00'),('2014/05/31 09:00','2014/06/28 09:00'),\n",
    "                  ('2014/12/16 09:00','2015/01/05 09:00'),('2015/01/12 09:00','2015/02/03 09:00'),\n",
    "                  ('2015/05/25 09:00','2015/06/16 09:00'),('2015/06/22 09:00','2015/07/14 09:00'),\n",
    "                  ('2015/07/20 09:00','2015/08/10 09:00')]\n",
    "    \n",
    "    if fme:\n",
    "        tFocus = [('2014/05/31 09:00','2014/06/28 09:00'),('2015/05/25 09:00','2015/06/16 09:00'),\n",
    "                  ('2015/06/22 09:00','2015/07/14 09:00'),('2015/07/20 09:00','2015/08/10 09:00')]\n",
    "    \n",
    "    if fmn:\n",
    "        tFocus = [('2014/01/11 09:00','2014/02/08 09:00'),('2014/12/16 09:00','2015/01/05 09:00'),\n",
    "                  ('2015/01/12 09:00','2015/02/03 09:00')]\n",
    "\n",
    "    \n",
    "    # Used for focus mode related filtering\n",
    "    drop = []\n",
    "    if fm or fmn or fme or nm:\n",
    "        for i in range(len(df)):\n",
    "            t = df['t_start'][i]\n",
    "            for focusMode in tFocus:\n",
    "                if (t > focusMode[0] and t < focusMode[1]) is not (fm or fmn or fme): \n",
    "                    if i not in drop:\n",
    "                        drop.append(i)\n",
    "                elif fm or fmn or fme:\n",
    "                    if i in drop:\n",
    "                        drop.remove(i)\n",
    "                    break;\n",
    "    \n",
    "    # Some of these flares can break the plots\n",
    "    for i,flare in df.iterrows():\n",
    "        if abs(flare['y']) > 900:\n",
    "            if i not in drop:\n",
    "                drop.append(i)\n",
    "    \n",
    "    # Filter out flares outside of time period and drop all flares that are being filtered for focus mode reasons\n",
    "    return df.drop(df.index[[drop]]).query('t_start > @time1 and t_start < @time2');\n",
    "\n",
    "def split_and_purge(in_str, delim=None, purge=[\"\", \"+\"]):\n",
    "    \"\"\"Split a string into an array of strings, removing unwanted strings.\"\"\"\n",
    "    pieces = []\n",
    "    if delim is None:\n",
    "        pieces = in_str.split()  # Split for both spaces and tabs.\n",
    "    else:\n",
    "        pieces = in_str.split(delim)\n",
    "    return [piece for piece in pieces if piece not in purge]\n",
    "\n",
    "def parseFlareResInfo(page):\n",
    "    '''Return document as a list of tuples of datetime objects: [(t_start,t_end),...]'''\n",
    "    lines = split_and_purge(page,delim='\\n')\n",
    "    output = []\n",
    "    for line in lines[7:]:\n",
    "        times = line.split()\n",
    "        t1 = datetime.datetime.strptime(times[0],'%Y-%m-%dT%H:%M:%S')\n",
    "        t2 = datetime.datetime.strptime(times[1],'%Y-%m-%dT%H:%M:%S')\n",
    "        output.append((t1.strftime('%Y/%m/%d %H:%M'),t2.strftime('%Y/%m/%d %H:%M')))\n",
    "    return output;\n",
    "\n",
    "def getFlareModeInfo(time1,time2):\n",
    "    '''Return a list of tuples of time (t_start,t_end) of flare responses between time1 and time2.\n",
    "    Arguments are datetime objects. time1 must be prior to time2'''\n",
    "    \n",
    "    # Reads text file and stores data in info -- a list of tuples of start and end times of XRT flare trigger \n",
    "    # responses\n",
    "    f = urllib2.urlopen('https://xrt.cfa.harvard.edu/missionops/flare_trigger_list/xrt_flare_responses.txt')\n",
    "    strio = StringIO(requests.get('https://xrt.cfa.harvard.edu/missionops/flare_trigger_list/xrt_flare_responses.txt').content)\n",
    "    flareFile = strio.read()\n",
    "    info = parseFlareResInfo(flareFile)\n",
    "    \n",
    "    output = []\n",
    "    # Filters out flares mode responses that occured outside of time1 to time2 range\n",
    "    for flare in info:\n",
    "        if time1.strftime('%Y/%m/%d %H:%M')<flare[0] and flare[0]<time2.strftime('%Y/%m/%d %H:%M'):\n",
    "            output.append(flare)\n",
    "\n",
    "    return output;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "\n",
    "def genHistogram(t_i,t_f,flareType,scale=False,data=pd.DataFrame(),save=False,show=True):\n",
    "    '''Create a JointGrid plot showing solar flares imaged and missed by XRT. A scatterplot indicates the locations\n",
    "    of flares on the sun and a heatmap indicates regions of high densities. A stacked histogram on both the x and y\n",
    "    axes depicts the number of flares that were imaged and that were missed.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    flareType -- A tuple used to filter out classes of flares\n",
    "    \n",
    "    Keyword arguments:\n",
    "    scale -- Scale the assignment of colormap values to the heatmap based on the number of flares (default False)\n",
    "    data -- A pandas dataframe of Hinode Flare Catalog data between t_i and t_f. Can be passed to speed up execution\n",
    "            (default empty pandas dataframe)\n",
    "    save -- A boolean indicating whether to save the generated plot (default False)\n",
    "    show -- A boolean indicating whether to show the generated plot (default True)'''\n",
    "    \n",
    "    if data.empty:\n",
    "        # Creates dataframe if not given as argument. If numerous plots are being generated, it saves a significant\n",
    "        # amount of time to call getXrtFlareCat once and to pass the dataframe to the plotting functions.\n",
    "        data = getXrtFlareCat(t_i,t_f)\n",
    "        print 'no data passed'\n",
    "    \n",
    "    # Creates dataframes of flare metadata for flares of specified class(es) depending on whether XRT imaged the flare\n",
    "    coorsXrt = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] > 0))][['x','y','XRT','t_start','t_end']]\n",
    "    coorsMissed = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] == 0))][['x','y','XRT']]\n",
    "    coorsAll = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])][['x','y','XRT']]\n",
    "    \n",
    "    # Creates JointGrid object and names figure and axes\n",
    "    g = sns.JointGrid(coorsXrt['x'],coorsXrt['y'],size=15,xlim=[-1050,1050],ylim=[-1050,1050],ratio=4)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    ax_sun = g.ax_joint\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "    \n",
    "    # Creates a background rectangle for aesthetic purposes and draws a circle to denote the sun\n",
    "    ax_sun.add_patch(plt.Rectangle((-1050,-1050),2100,2100,color='#fffddb',zorder=-1,alpha=1))\n",
    "    ax_sun.add_patch(plt.Circle((0,0),1920/2,color='black',alpha=1,zorder=1,fill=False))\n",
    "    \n",
    "    # Creates scatterplots showing flares imaged in red and missed in grey\n",
    "    g.plot_joint(plt.scatter,s=30,color='red',zorder=2)\n",
    "    ax_sun.scatter(coorsMissed['x'],coorsMissed['y'],s=30,color='grey',alpha=0.5,zorder=2)\n",
    "    \n",
    "    # Scales the heatmap based on total number of flares in scale=True is passed. Useful when generating movies.\n",
    "    # Scaling equation is currently intended for 6 month time windows. The exponent combats the very dark values\n",
    "    # otherwise present in plots with only a few dozen points that are very close together.\n",
    "    if scale:\n",
    "        vmin = 0\n",
    "        vmax = 0.0000013/len(coorsAll)**1.02*3000\n",
    "    else:\n",
    "        vmin = vmax = None\n",
    "    \n",
    "    # Creates the heatmap of all flares of specified classes within time range.\n",
    "    sns.kdeplot(coorsAll.dropna(subset=['x','y'],how='any')['x'],coorsAll.dropna(subset=['x','y'],how='any')['y'],\n",
    "                cmap='YlOrBr',zorder=1,shade=True,vmax=vmax,vmin=vmin)    \n",
    "    \n",
    "    # Creates stacked histograms. NaN's are dropped because they are handled poorly by plt.hist()\n",
    "    ax1.hist([coorsXrt['x'].dropna(),coorsMissed['x'].dropna()],stacked=True,\n",
    "                     bins=range(-1050,1100,50),color=['red','grey'])\n",
    "    ax2.hist([coorsXrt['y'].dropna(),coorsMissed['y'].dropna()],stacked=True,orientation='horizontal',\n",
    "                     bins=range(-1050,1100,50),color=['red','grey'])\n",
    "    \n",
    "    # Positions histogram tick marks\n",
    "    ymax1 = ax1.get_ylim()[1]\n",
    "    xmax1 = ax2.get_xlim()[1]\n",
    "\n",
    "    ax1.grid()\n",
    "    ax1.set_yticks(range(0,int(ymax1),50))\n",
    "    ax2.grid()\n",
    "    ax2.set_xticks(range(0,int(xmax1),50))\n",
    "    \n",
    "    \n",
    "    # Creates legend, title, and timestamp\n",
    "    ax_sun.add_patch(plt.Rectangle((425,950),75,75,color='red',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")]))\n",
    "    ax_sun.text(515,965,'Imaged: ' + str(len(coorsXrt)),size=25)\n",
    "\n",
    "    ax_sun.add_patch(plt.Rectangle((425,850),75,75,color='grey',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")]))\n",
    "    ax_sun.text(515,865,'Missed: ' + str(len(coorsMissed)),size=25)\n",
    "\n",
    "    title = flareType[0] + ' Flares Histogram'\n",
    "    fig.suptitle(title,size=50,x=0.46)\n",
    "    fig.text(.065,.05,t_i.strftime('%Y-%m-%d %H:%M')+' to '+t_f.strftime('%Y-%m-%d %H:%M'),size=25)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    # Closes figure. Memory leak nonetheless still exists as of 2015-07-28\n",
    "    fig.clf()\n",
    "    plt.close('all')\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genDistPlot(t_i,t_f,flareType,scale=False,data=pd.DataFrame(),save=False,show=True,bw=100):\n",
    "    '''Create a JointGrid plot showing solar flares imaged and missed by XRT. A scatterplot indicates the locations\n",
    "    of flares on the sun and a heatmap indicates regions of high densities. Spline curves depict the relative \n",
    "    densities of the sets all flare, imaged flares, and missed flares along both the x and y axes.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    flareType -- A tuple used to filter out classes of flares\n",
    "    \n",
    "    Keyword arguments:\n",
    "    scale -- Scale the assignment of colormap values to the heatmap based on the number of flares (default False)\n",
    "    data -- A pandas dataframe of Hinode Flare Catalog data between t_i and t_f. Can be passed to speed up execution\n",
    "            (default empty pandas dataframe)\n",
    "    save -- A boolean indicating whether to save the generated plot (default False)\n",
    "    show -- A boolean indicating whether to show the generated plot (default True)'''\n",
    "    \n",
    "    if data.empty:\n",
    "        # Creates dataframe if not given as argument. If numerous plots are being generated, it saves a significant\n",
    "        # amount of time to call getXrtFlareCat once and to pass the dataframe to the plotting functions.\n",
    "        data = getXrtFlareCat(t_i,t_f)\n",
    "        print 'no data passed'\n",
    "    \n",
    "    # Creates dataframes of flare metadata for flares of specified class(es) depending on whether XRT imaged the flare\n",
    "    coorsXrt = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] > 0))][['x','y','XRT','t_start','t_end']]\n",
    "    coorsMissed = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] == 0))][['x','y','XRT']]\n",
    "    coorsAll = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])][['x','y','XRT']]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    # Creates kdeplots that are used to create the spline curves\n",
    "    a = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw)\n",
    "    b = sns.kdeplot(coorsXrt['x'],color='red',legend=False,bw=bw)\n",
    "    try: # Program would otherwise fail if no flares were missed\n",
    "        c = sns.kdeplot(coorsMissed['x'],color='grey',legend=False,bw=bw)\n",
    "    except:\n",
    "        c = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw) \n",
    "        # Best way I could find to mark zero flares. This solution seems nonsensical, however it is not a\n",
    "        # straightfoward problem to solve because of the unusual behavior of the .get_lines()[i].get_data() \n",
    "        # function later on.\n",
    "    d = sns.kdeplot(coorsAll['y'],color='yellow',legend=False,bw=bw)\n",
    "    e = sns.kdeplot(coorsXrt['y'],color='red',legend=False,bw=bw)\n",
    "    try:\n",
    "        f = sns.kdeplot(coorsMissed['y'],color='grey',legend=False,bw=bw)\n",
    "    except:\n",
    "        f = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw)\n",
    "    \n",
    "    kdelist = [(a,coorsAll['x']),(b,coorsXrt['x']),(c,coorsMissed['x']),(d,coorsAll['y']),(e,coorsXrt['y']),(f,coorsMissed['y'])]\n",
    "\n",
    "    # Creates spline curves that are scaled relative to each other\n",
    "    xnew = range(-1050,1050,5)\n",
    "    splines = []\n",
    "    for i in range(len(kdelist)): #scales kdeplot data and creates spline curves\n",
    "        x = list(kdelist[i][0].get_lines()[i].get_data()[0])\n",
    "        y = list(kdelist[i][0].get_lines()[i].get_data()[1])\n",
    "        tempy=[]\n",
    "        for j in range(len(y)):\n",
    "            tempy.append(y[j] * len(kdelist[i][1]))\n",
    "        splines.append(spline(x,tempy,xnew))\n",
    "    \n",
    "    for axis in fig.axes:\n",
    "        axis.cla()\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Creates JointGrid object and names figure and axes\n",
    "    g = sns.JointGrid(coorsXrt['x'],coorsXrt['y'],size=15,xlim=[-1050,1050],ylim=[-1050,1050],ratio=4)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    ax_sun = g.ax_joint\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "    \n",
    "    # Creates a background rectangle for aesthetic purposes and draws a circle to denote the sun\n",
    "    ax_sun.add_patch(plt.Rectangle((-1050,-1050),2100,2100,color='#ffffe5',zorder=-1,alpha=1))\n",
    "    ax_sun.add_patch(plt.Circle((0,0),1920/2,color='black',alpha=1,zorder=1,fill=False))\n",
    "    \n",
    "    # Creates scatterplots showing flares imaged in red and missed in grey\n",
    "    g.plot_joint(plt.scatter,s=30,color='red',zorder=2)\n",
    "    ax_sun.scatter(coorsMissed['x'],coorsMissed['y'],s=30,color='grey',alpha=0.5,zorder=2)\n",
    "    \n",
    "    # Scales the heatmap based on total number of flares in scale=True is passed. Useful when generating movies.\n",
    "    # Scaling equation is currently intended for 6 month time windows. The exponent combats the very dark values\n",
    "    # otherwise present in plots with only a few dozen points that are very close together.\n",
    "    if scale:\n",
    "        vmin = 0\n",
    "        vmax = 0.0000013/len(coorsAll)**1.02*3000\n",
    "    else:\n",
    "        vmin = vmax = None\n",
    "    \n",
    "    # Creates the heatmap of all flares of specified classes within time range.\n",
    "    sns.kdeplot(coorsAll.dropna(subset=['x','y'],how='any')['x'],coorsAll.dropna(subset=['x','y'],how='any')['y'],\n",
    "                cmap='YlOrBr',zorder=1,shade=True,vmax=vmax,vmin=vmin)    \n",
    "\n",
    "    # Plots spline curves and shades underneath them\n",
    "    if scale:\n",
    "        ax1.axis([-1050,1050,0,0.5*3])\n",
    "        ax2.axis([0,4.0,-1050,1050])\n",
    "    \n",
    "    ax1.plot(xnew,splines[0],axes=ax1,color='yellow')\n",
    "    ax1.fill_between(xnew,0,list(splines[0]),color='yellow',alpha=0.3)\n",
    "\n",
    "    ax1.plot(xnew,splines[1],axes=ax1,color='red')\n",
    "    ax1.fill_between(xnew,0,list(splines[1]),color='red',alpha=0.3)\n",
    "\n",
    "    if list(splines[2]) != list(splines[0]):\n",
    "        ax1.plot(xnew,splines[2],axes=ax1,color='grey')\n",
    "        ax1.fill_between(xnew,0,list(splines[2]),color='grey',alpha=0.3)\n",
    "    \n",
    "    ax2.plot(splines[3],xnew,axes=ax2,color='yellow')\n",
    "    ax2.fill_between(list(splines[3]),1200,xnew,color='yellow',alpha=0.3)\n",
    "\n",
    "    ax2.plot(splines[4],xnew,axes=ax2,color='red')\n",
    "    ax2.fill_between(list(splines[4]),1200,xnew,color='red',alpha=0.3)\n",
    "\n",
    "    if splines[5].all() != splines[0].all():\n",
    "        ax2.plot(splines[5],xnew,axes=ax2,color='grey')\n",
    "        ax2.fill_between(list(splines[5]),1200,xnew,color='grey',alpha=0.3)    \n",
    "    \n",
    "    # Creates legend\n",
    "    ax_sun.add_patch(plt.Rectangle((425,950),75,75,color='yellow',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "    ax_sun.text(515,965,flareType[0]+' Flares: '+ str(len(coorsAll)),size=25,zorder=2)\n",
    "\n",
    "    ax_sun.add_patch(plt.Rectangle((425,850),75,75,color='red',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "    ax_sun.text(515,865,'Imaged: ' + str(len(coorsXrt)),size=25,zorder=2)\n",
    "    \n",
    "    ax_sun.add_patch(plt.Rectangle((425,750),75,75,color='grey',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "    ax_sun.text(515,765,'Missed: ' + str(len(coorsMissed)),size=25,zorder=2)\n",
    "\n",
    "    \n",
    "    title = flareType[0] + ' Flares'\n",
    "    fig.suptitle(title,size=50,x=0.42)\n",
    "    fig.text(.065,.05,t_i.strftime('%Y-%m-%d %H:%M:%S')+' to '+t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    # Closes plot (in theory). Memory leak nonetheless still exists as of 2015-07-28\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genProbPlot(t_i,t_f,flareType,scale=False,data=pd.DataFrame(),save=False,show=True,bw=100):\n",
    "    '''Create a JointGrid plot showing solar flares imaged and missed by XRT. A scatterplot indicates the locations\n",
    "    of flares on the sun and a heatmap indicates regions of high densities. A spline curve indicates the probability\n",
    "    of detecting a flare along the x axis.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    flareType -- A tuple used to filter out classes of flares\n",
    "    \n",
    "    Keyword arguments:\n",
    "    scale -- Scale the assignment of colormap values to the heatmap based on the number of flares (default False)\n",
    "    data -- A pandas dataframe of Hinode Flare Catalog data between t_i and t_f. Can be passed to speed up execution\n",
    "            (default empty pandas dataframe)\n",
    "    save -- A boolean indicating whether to save the generated plot (default False)\n",
    "    show -- A boolean indicating whether to show the generated plot (default True)'''\n",
    "    \n",
    "    if data.empty:\n",
    "        # Creates dataframe if not given as argument. If numerous plots are being generated, it saves a significant\n",
    "        # amount of time to call getXrtFlareCat once and to pass the dataframe to the plotting functions.\n",
    "        data = getXrtFlareCat(t_i,t_f)\n",
    "        print 'no data passed'\n",
    "    \n",
    "    # Creates dataframes of flare metadata for flares of specified class(es) depending on whether XRT imaged the flare\n",
    "    coorsXrt = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] > 0))][['x','y','XRT','t_start','t_end']]\n",
    "    coorsMissed = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] == 0))][['x','y','XRT']]\n",
    "    coorsAll = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])][['x','y','XRT']]\n",
    "    \n",
    "    # Creates kdeplots from which to pull unscaled datapoints for spline curves\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    a = sns.kdeplot(coorsAll['x'],color='yellow',bw=bw)\n",
    "    b = sns.kdeplot(coorsXrt['x'],color='red',bw=bw)\n",
    "    try:\n",
    "        c = sns.kdeplot(coorsMissed['x'],color='grey',bw=bw)\n",
    "    except:\n",
    "        c = sns.kdeplot(coorsAll['x'],color='yellow',bw=bw)\n",
    "    d = sns.kdeplot(coorsAll['y'],color='yellow',bw=bw)\n",
    "    e = sns.kdeplot(coorsXrt['y'],color='red',bw=bw)\n",
    "    try:\n",
    "        f = sns.kdeplot(coorsMissed['y'],color='grey',bw=bw)\n",
    "    except:\n",
    "        f = sns.kdeplot(coorsAll['x'],color='yellow',bw=bw)\n",
    "\n",
    "    kdelist = [(a,coorsAll['x']),(b,coorsXrt['x']),(c,coorsMissed['x']),(d,coorsAll['y']),\n",
    "               (e,coorsXrt['y']),(f,coorsMissed['y'])]\n",
    "\n",
    "    # Create scaled spline curves\n",
    "    xnew = range(-1050,1050,5)\n",
    "    splines = []\n",
    "    for i in range(len(kdelist)):\n",
    "        x = list(kdelist[i][0].get_lines()[i].get_data()[0])\n",
    "        y = list(kdelist[i][0].get_lines()[i].get_data()[1])\n",
    "        tempy=[]\n",
    "        for j in range(len(y)):\n",
    "            tempy.append(y[j] * len(kdelist[i][1])/len(coorsAll['x']))\n",
    "        splines.append(spline(x,tempy,xnew))\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Create JointGrid object and name figure and axes\n",
    "    g = sns.JointGrid(coorsXrt['x'],coorsXrt['y'],size=15,xlim=[-1050,1050],ylim=[-1050,1050],ratio=4)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    ax_sun = g.ax_joint\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "\n",
    "    ax_sun.add_patch(plt.Rectangle((-1050,-1050),2100,2100,color='#fffddb',zorder=-1,alpha=1))\n",
    "    ax_sun.add_patch(plt.Circle((0,0),1920/2,color='black',alpha=1,zorder=1,fill=False))\n",
    "\n",
    "    # Scale heatmap if scale=True is passed\n",
    "    if scale:\n",
    "        vmin = 0\n",
    "        vmax = 0.0000013/len(coorsAll)**1.02*3000\n",
    "    else:\n",
    "        vmin = vmax = None\n",
    "    \n",
    "    # Create primary plot features\n",
    "    g.plot_joint(plt.scatter,s=30,color='red',zorder=12)\n",
    "    sns.kdeplot(coorsAll.dropna(subset=['x','y'],how='any')['x'],coorsAll.dropna(subset=['x','y'],how='any')['y'],\n",
    "                cmap='YlOrBr',zorder=1,shade=True,vmax=vmax,vmin=vmin)\n",
    "    \n",
    "    ax_sun.scatter(coorsMissed['x'],coorsMissed['y'],s=30,color='grey',alpha=0.5,zorder=2)\n",
    "\n",
    "    \n",
    "    # Create secondary plot features\n",
    "    ax1.axis([-1050,1050,0,1])\n",
    "    ax1.plot(xnew,splines[1]/splines[0],color='red')\n",
    "    ax1.fill_between(xnew,0,list(splines[1]/splines[0]),color='red',alpha=0.3)\n",
    "    ax1.grid()\n",
    "\n",
    "    ax1.set_yticks([0.0,0.25,0.5,0.75,1.0])\n",
    "    \n",
    "    \n",
    "    # Create legends/titles/timestamp\n",
    "    ax_sun.add_patch(plt.Rectangle((425,950),75,75,color='red',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")]))\n",
    "    ax_sun.text(515,965,'Imaged: ' + str(len(coorsXrt)),size=25)\n",
    "\n",
    "    ax_sun.add_patch(plt.Rectangle((425,850),75,75,color='grey',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")]))\n",
    "    ax_sun.text(515,865,'Missed: ' + str(len(coorsMissed)),size=25)\n",
    "    \n",
    "    title = flareType[0] + ' Flare Imaging Probability'\n",
    "    fig.suptitle(title,size=50,x=0.42)\n",
    "    \n",
    "    fig.text(.065,.05,t_i.strftime('%Y-%m-%d %H:%M')+' to '+t_f.strftime('%Y-%m-%d %H:%M'),size=25)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genFlareResPlot(t_i,t_f,flareType,scale=False,data=pd.DataFrame(),save=False,show=True,bw=100):\n",
    "    '''Create a JointGrid plot showing solar flares imaged and missed by XRT. A scatterplot indicates the locations\n",
    "    of flares imaged by XRT, distinguishing between flares imaged as a result of normal pointings and flares\n",
    "    imaged in response to an XRT flare trigger\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    flareType -- A tuple used to filter out classes of flares\n",
    "    \n",
    "    Keyword arguments:\n",
    "    scale -- Scale the assignment of colormap values to the heatmap based on the number of flares (default False)\n",
    "    data -- A pandas dataframe of Hinode Flare Catalog data between t_i and t_f. Can be passed to speed up execution\n",
    "            (default empty pandas dataframe)\n",
    "    save -- A boolean indicating whether to save the generated plot (default False)\n",
    "    show -- A boolean indicating whether to show the generated plot (default True)'''\n",
    "    \n",
    "    if data.empty:\n",
    "        # Creates dataframe if not given as argument. If numerous plots are being generated, it saves a significant\n",
    "        # amount of time to call getXrtFlareCat once and to pass the dataframe to the plotting functions.\n",
    "        data = getXrtFlareCat(t_i,t_f)\n",
    "        print 'no data passed'\n",
    "    \n",
    "    # Creates dataframes of flare metadata for flares of specified class(es) depending on whether XRT imaged the flare\n",
    "    coorsXrt = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] > 0))][['x','y','XRT','t_start','t_end']]\n",
    "    coorsMissed = data[((data['class'] > flareType[1]) & (data['class'] < flareType[2]) & \n",
    "                     (data['XRT'] == 0))][['x','y','XRT']]\n",
    "    coorsAll = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])][['x','y','XRT']]\n",
    "    \n",
    "    # Create pandas dataframe of flare trigger response coordinates\n",
    "    flareResponseInfo = getFlareModeInfo(t_i,t_f)\n",
    "    flareResX = []\n",
    "    flareResY = []\n",
    "    for i,flare in coorsXrt.iterrows():\n",
    "        for response in flareResponseInfo:\n",
    "            if ((response[0] > flare['t_start'] and response[0] < flare['t_end']) or \n",
    "                (response[1] > flare['t_start'] and response[1] < flare['t_end'])):\n",
    "                \n",
    "                flareResX.append(flare['x'])\n",
    "                flareResY.append(flare['y'])\n",
    "                break;\n",
    "    \n",
    "    flareResponses=pd.DataFrame({'x':flareResX,'y':flareResY})\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    #Creates kdeplots\n",
    "    a = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw)\n",
    "    b = sns.kdeplot(coorsXrt['x'],color='red',legend=False,bw=bw)\n",
    "    try: #Program would otherwise fail if no flares were missed\n",
    "        c = sns.kdeplot(coorsMissed['x'],color='grey',legend=False,bw=bw)\n",
    "    except:\n",
    "        c = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw) \n",
    "        #Best way I could find to mark zero flares. This solution seems nonsensical, however it is not a straightforward\n",
    "        #problem to solve because of the unusual behavior of the .get_lines()[i].get_data() function later on.\n",
    "    d = sns.kdeplot(coorsAll['y'],color='yellow',legend=False,bw=bw)\n",
    "    e = sns.kdeplot(coorsXrt['y'],color='red',legend=False,bw=bw)\n",
    "    try:\n",
    "        f = sns.kdeplot(coorsMissed['y'],color='grey',legend=False,bw=bw)\n",
    "    except:\n",
    "        f = sns.kdeplot(coorsAll['x'],color='yellow',legend=False,bw=bw)\n",
    "\n",
    "    g = sns.kdeplot(flareResponses['x'],color='orange',legend=False,bw=bw)\n",
    "    h = sns.kdeplot(flareResponses['y'],color='orange',legend=False,bw=bw)\n",
    "\n",
    "    \n",
    "    \n",
    "    kdelist = [(a,coorsAll['x']),(b,coorsXrt['x']),(c,coorsMissed['x']),(d,coorsAll['y']),(e,coorsXrt['y']),\n",
    "               (f,coorsMissed['y']),(g,flareResponses['x']),(h,flareResponses['y'])]\n",
    "    \n",
    "    # Creates scaled spline curves\n",
    "    xnew = range(-1050,1050,5)\n",
    "    splines = []\n",
    "    for i in range(len(kdelist)):\n",
    "        x = list(kdelist[i][0].get_lines()[i].get_data()[0])\n",
    "        y = list(kdelist[i][0].get_lines()[i].get_data()[1])\n",
    "        tempy=[]\n",
    "        for j in range(len(y)):\n",
    "            tempy.append(y[j] * len(kdelist[i][1])/len(coorsAll['x']))\n",
    "        splines.append(spline(x,tempy,xnew))\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    # Create JointGrid object\n",
    "    g = sns.JointGrid(coorsXrt['x'],coorsXrt['y'],size=15,xlim=[-1050,1050],ylim=[-1050,1050],ratio=4)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    ax_sun = g.ax_joint\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "    \n",
    "    # The purpose of the unusually high zorder numbers is to hide unwanted features that I struggled with removing\n",
    "    ax_sun.add_patch(plt.Rectangle((-1050,-1050),2100,2100,color='#fffddb',zorder=10,alpha=0.7))\n",
    "    ax_sun.add_patch(plt.Circle((0,0),1920/2,color='black',alpha=1,zorder=12,fill=False))\n",
    "\n",
    "    # Scale heatmap if scale=True is passed\n",
    "    if scale:\n",
    "        vmin = 0\n",
    "        vmax = 0.0000013/len(coorsAll)**1.02*3000\n",
    "    else:\n",
    "        vmin = vmax = None\n",
    "    \n",
    "    # Creates primary plot features\n",
    "    g.plot_joint(plt.scatter,s=30,color='red',zorder=12,alpha=1)\n",
    "    sns.kdeplot(coorsXrt.dropna(subset=['x','y'],how='any')['x'],coorsXrt.dropna(subset=['x','y'],how='any')['y'],\n",
    "                cmap='YlOrBr',zorder=11,shade=True,vmax=vmax,vmin=vmin)\n",
    "\n",
    "    plt.scatter(flareResponses['x'],flareResponses['y'],s=30,color='orange',zorder=12,alpha=1)\n",
    "\n",
    "    \n",
    "    # Creates secondary plot features\n",
    "    ax1.axis([-1050,1050,0,max(splines[1])])\n",
    "\n",
    "    ax1.plot(xnew,splines[1],axes=ax1,color='red')\n",
    "    ax1.fill_between(xnew,0,list(splines[1]),color='red',alpha=0.3)\n",
    "        \n",
    "    if list(splines[6]) != list(splines[0]):\n",
    "        ax1.plot(xnew,splines[6],color='orange')\n",
    "        ax1.fill_between(xnew,0,list(splines[6]),color='orange',alpha=0.3)\n",
    "\n",
    "    ax2.plot(splines[4],xnew,axes=ax2,color='red')\n",
    "    ax2.fill_between(list(splines[4]),1200,xnew,color='red',alpha=0.3) \n",
    "    \n",
    "    if list(splines[7]) != list(splines[0]):\n",
    "        ax2.plot(splines[7],xnew,color='orange')\n",
    "        ax2.fill_between(list(splines[7]),1200,xnew,color='orange',alpha=0.3)\n",
    "    \n",
    "    # Creates legend, title, and timestamp\n",
    "    ax_sun.add_patch(plt.Rectangle((425,950),75,75,color='red',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=11))\n",
    "    ax_sun.text(515,965,'Imaged: ' + str(len(coorsXrt)),size=25,zorder=11)\n",
    "    \n",
    "    ax_sun.add_patch(plt.Rectangle((425,850),75,75,color='orange',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=11))\n",
    "    ax_sun.text(515,865,'FR Images: ' + str(len(flareResponses['x'])),size=25,zorder=11)\n",
    "\n",
    "    \n",
    "    title = flareType[0] + ' Flares FR Plot'\n",
    "    fig.suptitle(title,size=50,x=0.42)\n",
    "    fig.text(.065,.05,t_i.strftime('%Y-%m-%d %H:%M')+' to '+t_f.strftime('%Y-%m-%d %H:%M'),size=25)\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.close('all')\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not particularly useful\n",
    "\n",
    "def genFRPercentPlot(t_i,t_f,save=False,show=True):\n",
    "    '''Create a stacked bar plot showing the percent of flares imaged by XRT and the percent imaged during a flare\n",
    "    response. The bar plot is broken down by the classes of flares that occured in the time period of question.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    save -- A boolean indicating whether to save the resulting plot (default False)\n",
    "    show -- A boolean indicating whether to show the resulting plot (default True)'''\n",
    "    \n",
    "    # Create pandas dataframe of flare response instances\n",
    "    data = getXrtFlareCat(t_i,t_f)\n",
    "    flareResponses = data[data['response'] > 0]\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    \n",
    "    # Create and sort a list of classes of flares that occured, truncating to form C2, X3, etc.\n",
    "    powersAll = []\n",
    "    for flareClass in data['class']:\n",
    "        powersAll.append(flareClass.split('.')[0])\n",
    "    powersAll.sort()\n",
    "    \n",
    "    # Same as above but for flares imaged\n",
    "    powersXrt = []\n",
    "    for i,flare in data[data['XRT'] > 0].iterrows():\n",
    "        powersXrt.append(flare['class'].split('.')[0])\n",
    "    powersXrt.sort()\n",
    "    \n",
    "    # Same as above but for flares missed\n",
    "    powersFR = list(flareResponses['class'])\n",
    "    for i in range(len(powersFR)):\n",
    "        powersFR[i] = powersFR[i].split('.')[0]\n",
    "    powersFR.sort()\n",
    "    \n",
    "    indicesAll = []\n",
    "    freqsAll = []\n",
    "    for power in powersAll:\n",
    "        added = False\n",
    "        for i in range(len(indicesAll)):\n",
    "            if power == indicesAll[i]:\n",
    "                freqsAll[i] += 1.0\n",
    "                added = True\n",
    "        if not added:\n",
    "            indicesAll.append(power)\n",
    "            freqsAll.append(1.0)\n",
    "            \n",
    "    indicesXrt = indicesAll\n",
    "    freqsXrt = [0.0]*len(indicesAll)\n",
    "    for power in powersXrt:\n",
    "        for i in range(len(indicesXrt)):\n",
    "            if power == indicesXrt[i]:\n",
    "                freqsXrt[i] += 1.0\n",
    "    \n",
    "    indicesFR = indicesAll\n",
    "    freqsFR = [0.0]*len(indicesAll)\n",
    "    for power in powersFR:\n",
    "        for i in range(len(indicesFR)):\n",
    "            if power == indicesFR[i]:\n",
    "                freqsFR[i] += 1.0\n",
    "    \n",
    "    percentsXrt = []\n",
    "    for a,b in zip(freqsXrt,freqsAll):\n",
    "        try:\n",
    "            percentsXrt.append(a/b*100)\n",
    "        except ZeroDivisionError:\n",
    "            percentsXrt.append(0.0)\n",
    "    \n",
    "    percentsFR = []\n",
    "    for a,b in zip(freqsFR,freqsAll):\n",
    "        try:\n",
    "            percentsFR.append(a/b*100)\n",
    "        except ZeroDivisionError:\n",
    "            percentsFR.append(0.0)\n",
    "    \n",
    "    ind = np.arange(len(indicesAll))\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.bar(ind,percentsXrt,color='red',zorder=1)\n",
    "    ax.bar(ind,percentsFR,color='orange',zorder=2)\n",
    "    ax.set_xticks(ind+0.4)\n",
    "    ax.set_xticklabels(indicesAll,size=20)\n",
    "    ax.set_yticklabels(range(0,110,20),size=20)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('Flare Class',size=30)\n",
    "    ax.set_ylabel('Percent',size=30,rotation=90)\n",
    "    \n",
    "    title='Flare Imaging Success'\n",
    "    fig.suptitle(title, size=50)\n",
    "    \n",
    "    ax.text(.5,96,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25)\n",
    "    ax.add_patch(plt.Rectangle((.5,92),1,3,color='red',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "    ax.text(1.75,93,'Imaged',size=25,zorder=2)\n",
    "    \n",
    "    ax.add_patch(plt.Rectangle((.5,88),1,3,color='orange',\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "    ax.text(1.75,88,'FR Image',size=25,zorder=11)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clf()\n",
    "    plt.close('all')\n",
    "    \n",
    "    return 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genFRValuePlot(t_i,t_f,save=False,show=True):\n",
    "    '''Create stacked bar plots depicting the numbers of flares imaged by XRT and the number of flares imaged by\n",
    "    XRT as a flare response. Broken down into a class B and C plot and a class M and X plot.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    save -- A boolean indicating whether to save the resulting plots (default False)\n",
    "    show -- A boolean indicating whether to show the resulting plots (default True)'''\n",
    "    \n",
    "    data = getXrtFlareCat(t_i,t_f)\n",
    "    flareResponses = data[data['response'] > 0]\n",
    "    \n",
    "    powersAll = []\n",
    "    for flareClass in data['class']:\n",
    "        powersAll.append(flareClass.split('.')[0])\n",
    "    powersAll.sort()\n",
    "    \n",
    "    powersXrt = []\n",
    "    for i,flare in data[data['XRT'] > 0].iterrows():\n",
    "        powersXrt.append(flare['class'].split('.')[0])\n",
    "    powersXrt.sort()\n",
    "    \n",
    "    powersFR = list(flareResponses['class'])\n",
    "    for i in range(len(powersFR)):\n",
    "        powersFR[i] = powersFR[i].split('.')[0]\n",
    "    powersFR.sort()\n",
    "    \n",
    "    indicesAll = []\n",
    "    freqsAll = []\n",
    "    for power in powersAll:\n",
    "        added = False\n",
    "        for i in range(len(indicesAll)):\n",
    "            if power == indicesAll[i]:\n",
    "                freqsAll[i] += 1.0\n",
    "                added = True\n",
    "        if not added:\n",
    "            indicesAll.append(power)\n",
    "            freqsAll.append(1.0)\n",
    "            \n",
    "    indicesXrt = indicesAll\n",
    "    freqsXrt = [0.0]*len(indicesAll)\n",
    "    for power in powersXrt:\n",
    "        for i in range(len(indicesXrt)):\n",
    "            if power == indicesXrt[i]:\n",
    "                freqsXrt[i] += 1.0\n",
    "    \n",
    "    indicesFR = indicesAll\n",
    "    freqsFR = [0.0]*len(indicesAll)\n",
    "    for power in powersFR:\n",
    "        for i in range(len(indicesFR)):\n",
    "            if power == indicesFR[i]:\n",
    "                freqsFR[i] +=1.0\n",
    "    \n",
    "    for i in range(len(indicesAll)):\n",
    "        if indicesAll[i] > 'C9':\n",
    "            indices1 = indicesAll[:i]\n",
    "            freqsFR1 = freqsFR[:i]\n",
    "            freqsXrt1 = freqsXrt[:i]\n",
    "            freqsAll1 = freqsAll[:i]\n",
    "            indices2 = indicesAll[i:]\n",
    "            freqsFR2 = freqsFR[i:]\n",
    "            freqsXrt2 = freqsXrt[i:]\n",
    "            freqsAll2 = freqsAll[i:]\n",
    "            break;\n",
    "    \n",
    "    for indices,FR,Xrt,All in [(indices1,freqsFR1,freqsXrt1,freqsAll1),(indices2,freqsFR2,freqsXrt2,freqsAll2)]:\n",
    "        ind = np.arange(len(indices))\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "    \n",
    "        plt.bar(ind,All[:len(indices)],color='yellow',zorder=0)\n",
    "        ax = plt.gca()\n",
    "        ax.bar(ind,Xrt,color='red',zorder=1)\n",
    "        ax.bar(ind,FR,color='orange',zorder=2)\n",
    "        ax.set_xticks(ind+0.4)\n",
    "        ax.set_xticklabels(indices,size=20)\n",
    "        ax.grid()\n",
    "        ax.set_xlabel('Flare Class',size=30)\n",
    "        ax.set_ylabel('Number',size=30,rotation=90)\n",
    "        title = 'Flare Imaging Success'\n",
    "        fig.suptitle('Flare Imaging Success', size=50)\n",
    "\n",
    "        ax.text(.4,.97,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25,transform=ax.transAxes)\n",
    "        ax.add_patch(plt.Rectangle((0.8,.92),.03,.03,color='yellow',transform=ax.transAxes,\n",
    "                               path_effects=[PathEffects.withStroke(linewidth=2,foreground='black')],zorder=2))\n",
    "        ax.text(0.84,.93,'All',size=25,zorder=2,transform=ax.transAxes)\n",
    "        ax.add_patch(plt.Rectangle((.8,.88),.03,.03,color='red',transform=ax.transAxes,\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "        ax.text(.84,.89,'Imaged',size=25,zorder=2,transform=ax.transAxes)\n",
    "    \n",
    "        ax.add_patch(plt.Rectangle((.8,.84),.03,.03,color='orange',transform=ax.transAxes,\n",
    "                                    path_effects=[PathEffects.withStroke(linewidth=2,foreground=\"black\")],zorder=2))\n",
    "        ax.text(.84,.85,'FR Image',size=25,zorder=11,transform=ax.transAxes)\n",
    "    \n",
    "        if save:\n",
    "            plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        \n",
    "        fig.clf()\n",
    "        plt.close('all')\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not particularly useful\n",
    "\n",
    "def genObsNotesPlot(t_i,t_f,save=False,show=True):\n",
    "    '''Create stacked bar plots showing a breakdown of the obs_note metadata for flares missed by the XRT flare\n",
    "    response for different classes of flares. Broken down into a classes B and C plot and a classes M and X plot.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    save -- A boolean indicating whether to save the resulting plots (default False)\n",
    "    show -- A boolean indicating whether to show the resulting plots (default True)'''\n",
    "    \n",
    "    data = getXrtFlareCat(t_i,t_f)[['class','obs_note']]\n",
    "    \n",
    "    missed = data[data['obs_note']<'y']\n",
    "    \n",
    "    obs_notes = [('no:no_hk','blue'),('no:no_timeline','black'),('no:mode=1','lightsteelblue'),('no:no_obev','cyan'),\n",
    "                 ('no:orbital_event','magenta'),('no:calibration_seq','yellow'),('no:no_sci_images','red'),\n",
    "                 ('no:pointing','green'),('no:mode=7','darkgoldenrod'),('no:mode=3','darkred'),('no:mode=5','khaki')]\n",
    "    \n",
    "    classes = []\n",
    "    for i,flare in missed.iterrows():\n",
    "        if flare['class'] not in classes:\n",
    "            classes.append(flare['class'].split('.')[0])\n",
    "    classes.sort()\n",
    "    \n",
    "    d1 = {flareClass:[] for flareClass in classes}\n",
    "    for i,flare in missed.iterrows():\n",
    "        d1[flare['class'].split('.')[0]].append(flare['obs_note'])\n",
    "    \n",
    "    d2 = {flareClass:[] for flareClass in classes}    \n",
    "    for i,e in zip(d1.keys(),d1.values()):\n",
    "        for note in e[:]:\n",
    "            if note == 'no:saa' or note == 'no:ngt' or note == 'no:xtw':\n",
    "                d2[i].append('no:orbital_event')\n",
    "            elif note == 'no:calibration' or note == 'no:bakeout' or note == 'no:gband_only':\n",
    "                d2[i].append('no:calibration_seq')\n",
    "            elif note == 'no:fld_only' or note == 'no:no_obs_planned':\n",
    "                d2[i].append('no:no_sci_images')\n",
    "            else:\n",
    "                d2[i].append(note)\n",
    "                \n",
    "    d3 = {flareClass:{note:0 for note in d2[flareClass]} for flareClass in d2.keys()}\n",
    "    for i,e in zip(d2.keys(),d2.values()):\n",
    "        for note in e:\n",
    "            d3[i][note] += 1\n",
    "    \n",
    "    list3 = d3.keys()\n",
    "    list3.sort()\n",
    "\n",
    "    for i in range(len(list3)):\n",
    "        if list3[i]>'C9':\n",
    "            list2 = [list3[:i],list3[i:]]\n",
    "            break;\n",
    "    \n",
    "    leg = []\n",
    "    for list1 in list2:\n",
    "        fig = plt.figure(figsize=(15,15))\n",
    "        ind = np.arange(len(list1))\n",
    "        bottom = [0]*len(list1)\n",
    "        for note in obs_notes:\n",
    "            heights = []\n",
    "            for c in list1:\n",
    "                try:\n",
    "                    heights.append(d3[c][note[0]])\n",
    "                except KeyError:\n",
    "                    heights.append(0)\n",
    "            b = plt.bar(ind,heights,bottom=bottom,color=note[1])\n",
    "            leg.append(b[0])\n",
    "            for i in range(len(bottom)):\n",
    "                bottom[i] = bottom[i] + heights[i]\n",
    "        plt.legend(leg,['no:no_hk','no:no_timeline','no:mode=1','no:no_obev','no:orbital_event','no:calibration_seq',\n",
    "                            'no:no_sci_images','no:pointing','no:mode=7','no:mode=3','no:mode=5'],fontsize=20)\n",
    "        plt.legend()\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticks(ind+.4)\n",
    "        ax.set_xticklabels(list1,size=20)\n",
    "        title = 'FR Failure Reasons'\n",
    "        plt.suptitle(title,size=50)\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        \n",
    "        fig.clf()\n",
    "        plt.close('all')\n",
    "\n",
    "    return 0;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObsNotesClassPlot(t_i,t_f,flareType,save=False,show=True):\n",
    "    '''Create a horizontal bar plot for the specified class of solar flares showing the quantity of flares that did\n",
    "    not trigger a flare response broken down by obs_note metadata information.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- The initial time boundary (datetime object)\n",
    "    t_f -- The final time boundary (datetime object)\n",
    "    flareType -- Tuple indicating flare class(es) of interest e.g. ('C5 to X','C','Z')\n",
    "    \n",
    "    Keyword arguments:\n",
    "    save -- A boolean indicating whether or not to save the resulting plot (default False)\n",
    "    show -- A boolean indicating whether or not to show the resulting plot (default True)'''\n",
    "    \n",
    "    # Get data\n",
    "    data = getXrtFlareCat(t_i,t_f)[['class','obs_note','t_start','x','y']].reset_index(drop=True)\n",
    "    \n",
    "    # Clarify vague obs_notes\n",
    "    for i,flare in data.iterrows():\n",
    "        if flare['t_start'] in reasons1415.keys():\n",
    "            data.set_value(i,'obs_note',reasons1415[flare['t_start']])\n",
    "\n",
    "    missed = data[(data['obs_note'] < 'y') & (data['class'] > flareType[1]) & (data['class'] < flareType[2])]\n",
    "    \n",
    "    # Dictionary to store counts of occurrences and colors\n",
    "    reasons = {'no:no_hk':[0,'blue'],'no:no_timeline':[0,'black'],'no:mode=1':[0,'lightsteelblue'],'no:no_obev':[0,'cyan'],\n",
    "               'no:pointing_out':[0,'darkgreen'],'no:cal_seq':[0,'yellow'],'no:no_sci':[0,'red'],'no:orbital_event':[0,'magenta'],\n",
    "               'no:mode=7':[0,'darkgoldenrod'],'no:mode=3':[0,'darkred'],'no:mode=5':[0,'khaki'],'no:bakeout':[0,'orange'],\n",
    "               'no:seu':[0,'grey'],'no:mwm':[0,'violet'],'no:dam':[0,'lightblue'],'no:op_error':[0,'purple'],\n",
    "               'no:missing_data':[0,'black'],'no:pointing_in':[0,'lightgreen'],'no:HOP_70/130':[0,'darkgoldenrod']}\n",
    "\n",
    "    # Precompute concatFile for splitByPointings\n",
    "    concatFile = getPointingFileInfo(t_i,t_f)\n",
    "    \n",
    "    # Split pointing failures based on whether the flare occurred on the CCD FOV or not\n",
    "    sepPointings = splitByPointings(missed,['no:pointing'],pointings=concatFile)\n",
    "\n",
    "    for i,flare in sepPointings[0].iterrows():\n",
    "        missed.set_value(i,'obs_note','no:pointing_in')\n",
    "    for i,flare in sepPointings[1].iterrows():\n",
    "        missed.set_value(i,'obs_note','no:pointing_out')\n",
    "        \n",
    "    # Pull out failures due to HOP 70 and HOP 130 routines, as requested\n",
    "    no_obs_planned = []\n",
    "    \n",
    "    for i,flare in missed.iterrows():\n",
    "        if flare['obs_note'] == 'no:no_obs_planned':\n",
    "            if isHOP79or130(datetime.datetime.strptime(flare['t_start'],'%Y/%m/%d %H:%M')):\n",
    "                missed.set_value(i,'obs_note','no:HOP_70/130')\n",
    "    \n",
    "    # Group and count obs_notes\n",
    "    for note in missed['obs_note']:\n",
    "        if note == 'no:saa' or note == 'no:ngt' or note == 'no:xtw':\n",
    "            reasons['no:orbital_event'][0] += 1\n",
    "        elif note == 'no:calibration' or note == 'no:gband_only':\n",
    "            reasons['no:cal_seq'][0] += 1\n",
    "        elif note == 'no:fld_only' or note == 'no:no_obs_planned':\n",
    "            reasons['no:no_sci'][0] += 1\n",
    "        else:\n",
    "            reasons[note][0] += 1\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Create bar graph\n",
    "    ind = np.arange(len([e for e in reasons.values() if e[0] != 0]))\n",
    "    ax.barh(ind,[e[0] for e in sorted(reasons.values()) if e[0] != 0],\n",
    "            color=[e[1] for e in sorted(reasons.values()) if e[0] != 0])\n",
    "    \n",
    "    # Format graph and add title and labels\n",
    "    ax.set_yticks(ind + .4)\n",
    "    ax.set_yticklabels([i[3:] for k,i in sorted(zip(reasons.values(),reasons.keys())) if reasons[i][0] != 0],size=25)\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=25)\n",
    "    ax.grid()\n",
    "    \n",
    "    ax.text(.4,.01,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25,\n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "    title = flareType[0] + ' Flare FR Failure Reasons'\n",
    "    fig.suptitle(title, size=50)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close('all')\n",
    "\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObsNoteDistPlot(t_i,t_f,flareType,scale=False,save=False,show=True,bw=100):\n",
    "    '''Create a plot showing the latitudinal and longitudinal distributions of flare obs_notes (some grouped/split).\n",
    "    Any obs_note that doesn't account for >10% of flares is grouped into 'no:other'.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- Initial time (datetime object)\n",
    "    t_f -- Final time (datetime object)\n",
    "    flareType -- Tuple indicating the type(s) of flares and the two bounds for flare['class'] ('M','M','X')\n",
    "    \n",
    "    Keyword arguments:\n",
    "    save -- Boolean indicating whether to save the figure (default False)\n",
    "    show -- Boolean indicating whether to show the figure (default True)'''\n",
    "    \n",
    "    h = ColorConverter()\n",
    "    \n",
    "    # Dictionary for colors\n",
    "    reasons = {'no:no_hk': 'blue','no:no_timeline': 'black','no:wrong_mode': 'darkred','no:no_obev': 'cyan',\n",
    "               'no:pointing_out': 'green','no:cal_seq': 'yellow','no:no_sci': 'red','no:orbital_event': 'magenta',\n",
    "               'no:other': 'grey','no:bakeout': 'orange','no:pointing_in': 'lightgreen'}\n",
    "    \n",
    "    # Get data\n",
    "    data = getXrtFlareCat(t_i,t_f)[['x','y','class','obs_note','t_start']]\n",
    "    missed = data[(data['obs_note'] < 'y') & (data['class'] > flareType[1]) & (data['class'] < flareType[2])]\n",
    "    \n",
    "    # Split pointing failures based on whether flare occurred within the FOV of the CDD\n",
    "    pointings = []\n",
    "    for i,flare in missed.iterrows():\n",
    "        if flare['obs_note'] == 'no:pointing':\n",
    "            pointings.append((flare['x'],flare['y'],datetime.datetime.strptime(flare['t_start'],'%Y/%m/%d %H:%M'),i))\n",
    "    \n",
    "    sepPointings = sepPointingFailures(pointings)\n",
    "    \n",
    "    for inPointing in sepPointings[0]:\n",
    "        missed.set_value(inPointing[3],'obs_note','no:pointing_in')\n",
    "    for outPointing in sepPointings[1]:\n",
    "        missed.set_value(outPointing[3],'obs_note','no:pointing_out')\n",
    "    \n",
    "    \n",
    "    # Group datapoints by obs_note\n",
    "    d = {}\n",
    "    for i,flare in missed.iterrows():\n",
    "        if flare['obs_note'] not in d.keys():\n",
    "            if flare['obs_note'] in ['no:saa','no:ngt','no:xtw']:\n",
    "                if 'no:orbital_event' in d.keys():\n",
    "                    d['no:orbital_event'].append((flare['x'],flare['y']))\n",
    "                else:\n",
    "                    d['no:orbital_event'] = [(flare['x'],flare['y'])]\n",
    "            elif flare['obs_note'] in ['no:calibration','no:gband_only']:\n",
    "                if 'no:cal_seq' in d.keys():\n",
    "                    d['no:cal_seq'].append((flare['x'],flare['y']))\n",
    "                else:\n",
    "                    d['no:cal_seq'] = [(flare['x'],flare['y'])]\n",
    "            elif flare['obs_note'] in ['no:fld_only','no:no_obs_planned']:\n",
    "                if 'no:no_sci' in d.keys():\n",
    "                    d['no:no_sci'].append((flare['x'],flare['y']))\n",
    "                else:\n",
    "                    d['no:no_sci'] = [(flare['x'],flare['y'])]\n",
    "            elif flare['obs_note'][:8] == 'no:mode=':\n",
    "                if 'no:wrong_mode' in d.keys():\n",
    "                    d['no:wrong_mode'].append((flare['x'],flare['y']))\n",
    "                else:\n",
    "                    d['no:wrong_mode'] = [(flare['x'],flare['y'])]\n",
    "            else:\n",
    "                d[flare['obs_note']] = [(flare['x'],flare['y'])]\n",
    "        else:\n",
    "            d[flare['obs_note']].append((flare['x'],flare['y']))\n",
    "    \n",
    "    # Filter out obs_notes note responsible for <10% of FR failures\n",
    "    d['no:other'] = []\n",
    "    for i in d.keys():\n",
    "        if len(d[i]) < 0.1*len(missed) and (i != 'no:other'):\n",
    "            for e in d[i]:\n",
    "                d['no:other'].append(e)\n",
    "            del d[i]\n",
    "    \n",
    "    # Create spline curves from kdeplot information\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    splinesh = []\n",
    "    splinesv = []\n",
    "    xnew = range(-1050,1050,5)\n",
    "    for i,key in zip(range(0,len(d)*2,2),d.keys()):\n",
    "        kdeplot = sns.kdeplot(np.asarray([float(coor[0]) for coor in d[key]]),bw=bw)\n",
    "        x_h = np.asarray(kdeplot.get_lines()[i].get_data()[0][:])\n",
    "        y_h = np.asarray(kdeplot.get_lines()[i].get_data()[1][:])\n",
    "        \n",
    "        kdeplot = sns.kdeplot(np.asarray([float(coor[1]) for coor in d[key]]),bw=bw)\n",
    "        x_v = np.asarray(kdeplot.get_lines()[i+1].get_data()[0][:])\n",
    "        y_v = np.asarray(kdeplot.get_lines()[i+1].get_data()[1][:])\n",
    "        \n",
    "        y_h_scaled = len(d[key])*y_h\n",
    "        y_v_scaled = len(d[key])*y_v\n",
    "\n",
    "        splinesh.append((spline(x_h,y_h_scaled,xnew),len(d[key]),key,np.std(y_h_scaled)))\n",
    "        splinesv.append((spline(x_v,y_v_scaled,xnew),len(d[key]),key,np.std(y_h_scaled)))\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    splinesh = [(e[0],e[2]) for e in sorted(splinesh,key=itemgetter(3))]\n",
    "    splinesh2 = [np.asarray([0.0]*len(xnew))]*len(splinesh)\n",
    "    \n",
    "    splinesv = [(e[0],e[2]) for e in sorted(splinesv,key=itemgetter(3))]\n",
    "    splinesv2 = [np.asarray([0.0]*len(xnew))]*len(splinesv)\n",
    "    \n",
    "    for i in range(len(splinesh)):\n",
    "        splinesh2[i]=splinesh[i][0]+splinesh2[i-1]\n",
    "        splinesv2[i]=splinesv[i][0]+splinesv2[i-1]\n",
    "    \n",
    "    # Create JointGrid object and name figure and axes\n",
    "    g = sns.JointGrid(missed['x'],missed['y'],size=15,xlim=[-1050,1050],ylim=[-1050,1050],ratio=4)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    ax_sun = g.ax_joint\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "    \n",
    "    # Create a background rectangle for aesthetic purposes and draws a circle to denote the sun\n",
    "    ax_sun.add_patch(plt.Rectangle((-1050,-1050),2100,2100,color='#fffddb',zorder=-1,alpha=1))\n",
    "    ax_sun.add_patch(plt.Circle((0,0),1920/2,color='black',alpha=1,zorder=1,fill=False))\n",
    "    \n",
    "    # Create scatterplots\n",
    "    leg = []\n",
    "    for key in d.keys():\n",
    "        scatter = ax_sun.scatter([e[0] for e in d[key]],[e[1] for e in d[key]],s=40,facecolor=reasons[key],alpha=0.7,zorder=2)\n",
    "        leg.append(scatter)\n",
    "    \n",
    "    # Scale the heatmap based on total number of flares in scale=True is passed. Useful when generating movies.\n",
    "    # Scaling equation is currently intended for 6 month time windows. The exponent combats the very dark values\n",
    "    # otherwise present in plots with only a few dozen points that are very close together.\n",
    "    if scale:\n",
    "        vmin = 0\n",
    "        vmax = 0.0000013/len([e for e in [d[key] for key in d.keys()]])**1.02*3000\n",
    "    else:\n",
    "        vmin = vmax = None  \n",
    "    \n",
    "    # Create heatmap\n",
    "    g.plot_joint(sns.kdeplot,shade=True,cmap='YlOrBr',vmin=vmin,vmax=vmax)\n",
    "    \n",
    "    # Draw spline curves and shades between them\n",
    "    \n",
    "    if scale:\n",
    "        ax1.axis([-1050,1050,0,0.5*3])\n",
    "\n",
    "    if scale:\n",
    "        ax2.axis([0,4.0,-1050,1050])\n",
    "        \n",
    "    for i in range(len(splinesh2)):\n",
    "        ax1.plot(xnew,splinesh2[i],color=reasons[splinesh[i][1]])\n",
    "        if i == 0:\n",
    "            ax1.fill_between(xnew,splinesh2[i],color=reasons[splinesh[i][1]],alpha=0.4)\n",
    "        else:\n",
    "            ax1.fill_between(xnew,splinesh2[i],splinesh2[i-1],color=reasons[splinesh[i][1]],alpha=0.4)\n",
    "            \n",
    "    for i in range(len(splinesh2)-1,-1,-1):\n",
    "        ax2.plot(splinesv2[i],xnew,color=reasons[splinesv[i][1]])\n",
    "        if i == 0:\n",
    "            rgb1 = h.to_rgb(reasons[splinesv[i][1]])\n",
    "            rgb2 = tuple(0.4*val+0.6 for val in rgb1)\n",
    "            ax2.fill_between(splinesv2[i],xnew,color=rgb2)\n",
    "        else:\n",
    "            rgb1 = h.to_rgb(reasons[splinesv[i][1]])\n",
    "            rgb2 = tuple(0.4*val+0.6 for val in rgb1)\n",
    "            ax2.fill_between(splinesv2[i],xnew,1200,color=rgb2)\n",
    "    \n",
    "    ax_sun.legend(leg,[key[3:] + ': ' + str(len(d[key])) for key in d.keys()],fontsize=20,markerscale=3)\n",
    "\n",
    "    ax_sun.text(.01,.01,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25,\n",
    "            transform=ax_sun.transAxes)\n",
    "    title = flareType[0] + ' Flare FR Failures Dist'\n",
    "    fig.suptitle(title,size=50,x=0.42)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close('all')\n",
    "\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sepPointingFailures(pFailures):\n",
    "    '''Return a list of lists that breaks no:pointing failures down based on whether the flare happened within\n",
    "    the field of view of XRT. Assumes outField if no FLD patrol image found in directory. [inField,outField]\n",
    "    \n",
    "    Argument:\n",
    "    pFailures -- list of tuples of pointing failure flare metadata (x,y,'%Y/%m/%d %H:%M',i)'''\n",
    "    \n",
    "    inField = []\n",
    "    outField = []\n",
    "    \n",
    "    nonFld = 0\n",
    "    noFld = 0\n",
    "    \n",
    "    for pointing in pFailures[:]:\n",
    "        directory = pointing[2].strftime('/archive/hinode/xrt/level0/%Y/%m/%d/H%H00/')\n",
    "        a = walk(directory)\n",
    "        least = [None,100]\n",
    "        \n",
    "        for root,dirs,files in a:\n",
    "            # File size is used to determine whether file is FLD patrol image. This is far faster than\n",
    "            # opening the header to check if it actually is. However, a few 256x256 science images are\n",
    "            # accidentally included. These are dropped later. FLD patrol images are desired because the\n",
    "            # xcen ycen metadata provide the simplest and most accurate way of determining the FOV of XRT\n",
    "            for fname in files:\n",
    "                diff = abs(int(fname[12:16])-int(pointing[2].strftime('%H%M')))\n",
    "                if diff < least[1] and abs(path.getsize(root + fname) - 147000) < 1000:\n",
    "                    least = [root+fname,diff]\n",
    "                if not least[1]:\n",
    "                    break;\n",
    "                if least[0] is None and fname == files[-1]:\n",
    "                    for fname2 in files:\n",
    "                        diff = abs(int(fname[12:16])-int(pointing[2].strftime('%H%M')))\n",
    "                        if diff < least[1]:\n",
    "                            least = [root+fname2,diff]\n",
    "                        if not least[1]:\n",
    "                            break;\n",
    "\n",
    "        if least[0] is not None: # Sometimes no FLD patrol images are taken\n",
    "            f = pyfits.open(least[0])\n",
    "            \n",
    "            xcen = f[0].header['xcen']\n",
    "            ycen = f[0].header['ycen']\n",
    "            \n",
    "            ccd_xcen = f[0].header['sc_attx'] - 40\n",
    "            ccd_ycen = f[0].header['sc_atty'] - 22\n",
    "            \n",
    "            # Use less accurate sc_att header entries (adjusted) for 256x256 science images\n",
    "            if f[0].header['chip_sum'] != 8:\n",
    "                nonFld += 1\n",
    "                if abs(ccd_xcen-pointing[0]) > 1.0286*1024 or abs(ccd_ycen-pointing[1]) > 1.0286*1024:\n",
    "                    outField.append(pointing)\n",
    "                else:\n",
    "                    inField.append(pointing)\n",
    "                \n",
    "            # Assign flare to appropriate list\n",
    "            elif abs(xcen-pointing[0]) > 1.0286*1024 or abs(ycen-pointing[1]) > 1.0286*1024:\n",
    "                outField.append(pointing)\n",
    "            else:\n",
    "                inField.append(pointing)\n",
    "                #print max(abs(xcen-pointing[0]),abs(ycen-pointing[1]))\n",
    "                \n",
    "            f.close()\n",
    "            \n",
    "        else:\n",
    "            noFld += 1\n",
    "            outField.append(pointing)\n",
    "\n",
    "    print 'non-FLD patrol images used: ' + str(nonFld)\n",
    "    print 'no data found: ' + str(noFld)\n",
    "    \n",
    "    return [inField,outField];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCCDCoords(t_i,t_f,data1,flareType,pointings=None,filterList=None):\n",
    "    '''Return DataFrame of flares that occurred in FOV of CCD. flare['x'] and flare['y'] replaced with CCD coordinates\n",
    "    by pixel from the bottom left corner.'''\n",
    "    \n",
    "    data = data1[(data1['class'] > flareType[1]) & (data1['class'] < flareType[2])]\n",
    "    print 'filtered by class'\n",
    "    \n",
    "    if pointings is None:\n",
    "        pointings = getPointingFileInfo(t_i,t_f)\n",
    "        print 'generated pointings'\n",
    "    \n",
    "    # Much faster to append to list and then create DataFrame than to use DataFrame operations\n",
    "    dataFilteredList = []\n",
    "    \n",
    "    # Filter out conditions where Hinode pointing may have intentionally been bad for the XRT FOV\n",
    "    if filterList is not None:\n",
    "        for i,flare in data.iterrows():\n",
    "            if flare['obs_note'] in filterList:\n",
    "                dataFilteredList.append([i] + list(flare))\n",
    "        dataFiltered = pd.DataFrame(dataFilteredList,columns=['index'] + list(data.columns))\n",
    "    else:\n",
    "        dataFiltered = data.copy()\n",
    "        \n",
    "    print 'filtered by obs_note'\n",
    "\n",
    "    # Iterate through data, finding the appropriate pointing and evaluating whether the flare was in XRT's FOV\n",
    "    for i,flare in dataFiltered.iterrows():\n",
    "        \n",
    "        if not i%10:\n",
    "            print i\n",
    "        \n",
    "        j = len(pointings)/2\n",
    "        j_min = 0\n",
    "        j_max = len(pointings)\n",
    "    \n",
    "        a = pointings['Start Time'][j] < flare['t_start']\n",
    "        b = pointings['Start Time'][j + 1] > flare['t_start']\n",
    "    \n",
    "        # Binary search through up to 20,000+ pointings (1000x faster than sequential in this case)\n",
    "        while a is not b: # Simplest way to use logical xor in python\n",
    "            if not a:\n",
    "                j_max = j\n",
    "                j = (j_min + j_max)/2\n",
    "            else:\n",
    "                j_min = j\n",
    "                j = (j_min + j_max)/2\n",
    "        \n",
    "            a = pointings['Start Time'][j] < flare['t_start']\n",
    "            b = pointings['Start Time'][j + 1] > flare['t_start']\n",
    "\n",
    "        x = abs(float(pointings['Xpointing'][j][:-1]) - 40 - flare['x']) < 1024 * 1.0286\n",
    "        y = abs(pointings['Ypointing'][j] - 22 - flare['y']) < 1024 * 1.0286\n",
    "        \n",
    "        # Convert to CCD coordinate system\n",
    "        # The 40\" and 22\" offsets are because XRT isn't perfectly parallel to Hinode\n",
    "        xcen_ccd = float(pointings['Xpointing'][j][:-1]) - 40\n",
    "        ycen_ccd = float(pointings['Ypointing'][j]) - 22\n",
    "        x = (flare['x'] - (xcen_ccd - (1024*1.0286)))/1.0286\n",
    "        y = (flare['y'] - (ycen_ccd - (1024*1.0286)))/1.0286\n",
    "        \n",
    "        # Replace sun-centric coordinates with CCD pixel locations\n",
    "        data.set_value(i,'x',x)\n",
    "        data.set_value(i,'y',y)\n",
    "    \n",
    "    \n",
    "    #nonFld = 0\n",
    "    #noFld = 0\n",
    "    \n",
    "    #for i,flare in data.iterrows():\n",
    "    #    date = datetime.datetime.strptime(flare['t_start'],'%Y/%m/%d %H:%M')\n",
    "    #    directory = date.strftime('/archive/hinode/xrt/level0/%Y/%m/%d/H%H00/')\n",
    "    #    a = walk(directory)\n",
    "    #    least = [None,100]\n",
    "    #    for root,dirs,files in a:\n",
    "            # File size is used to determine whether file is FLD patrol image. This is far faster than\n",
    "            # opening the header to check if it actually is. However, a few 256x256 science images are\n",
    "            # accidentally included. These are dropped later. FLD patrol images are desired because the\n",
    "            # xcen ycen metadata provide the simplest and most accurate way of determining the FOV of XRT\n",
    "    #        for fname in files:\n",
    "    #            diff = abs(int(fname[12:16])-int(date.strftime('%H%M')))\n",
    "    #            if diff < least[1] and path.getsize(root + fname) == 146880:\n",
    "    #                least = [root + fname,diff]\n",
    "    #            if not least[1]:\n",
    "    #                break;\n",
    "    #            if least[0] is None and fname == files[-1]:\n",
    "    #                for fname2 in files:\n",
    "    #                    diff = abs(int(fname[12:16])-int(date.strftime('%H%M')))\n",
    "    #                    if diff < least[1]:\n",
    "    #                        least = [root+fname2,diff]\n",
    "    #                    if not least[1]:\n",
    "    #                        break;\n",
    "\n",
    "                    \n",
    "    #    if least[0] is not None: # Sometimes no FLD patrol images are taken\n",
    "    #        f = pyfits.open(least[0])\n",
    "            \n",
    "    #        xcen = float(f[0].header['xcen'])\n",
    "    #        ycen = float(f[0].header['ycen'])\n",
    "            \n",
    "    #        ccd_xcen = f[0].header['sc_attx'] - 40\n",
    "    #        ccd_ycen = f[0].header['sc_atty'] - 22\n",
    "            \n",
    "            \n",
    "            # Use less accurate sc_att header entries (adjusted) for 256x256 science images\n",
    "    #        if f[0].header['chip_sum'] != 8:\n",
    "    #            nonFld += 1\n",
    "    #            xcen = ccd_xcen\n",
    "    #            ycen = ccd_ycen\n",
    "            \n",
    "            # xzero and yzero are the x y locations of the bottom left corner of the CCD FOV in arcseconds\n",
    "    #        xzero = xcen - 1.0286*1024\n",
    "    #        yzero = ycen - 1.0286*1024\n",
    "            \n",
    "            # Drop flares that occur outside of the CCD\n",
    "    #        if (abs(xcen-flare['x']) > 1.0286*1024) or (abs(ycen-flare['y']) > 1.0286*1024):\n",
    "    #            data.drop(i,inplace=True)\n",
    "    #        else:\n",
    "                # Replace x and y coordinate values in dataframe data with CCD coordinates from bottom left corner\n",
    "    #            data.set_value(i,'x',int((flare['x'] - xzero)/1.0286))\n",
    "    #            data.set_value(i,'y',int((flare['y'] - yzero)/1.0286))\n",
    "    #        f.close()\n",
    "\n",
    "    #    else:\n",
    "            # Drop flares for which no FLD patrol images are found and alert user\n",
    "    #        data.drop(i,inplace=True)\n",
    "    #        noFld += 1\n",
    "    \n",
    "    #print 'non-FLD patrol images used: ' + str(nonFld)\n",
    "    #print 'no data found: ' + str(noFld)\n",
    "    \n",
    "    return data;\n",
    "\n",
    "t_i = datetime.datetime(2014,1,1)\n",
    "t_f = datetime.datetime.utcnow()\n",
    "print getCCDCoords(t_i,t_f,getXrtFlareCat(t_i,t_f),('M','M','X'))\n",
    "\n",
    "def genCCDPlot(t_i,t_f,flareType,show=True,save=False,pointings=None):\n",
    "    '''Create a JointGrid plot of XRT flare hits and misses based on flare location on the CCD.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- Initial time boundary (datetime object)\n",
    "    t_f -- Final time boundary (datetime object)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    flareType -- Tuple indicating range of flares classes of interest (default ('All','B','Z'))\n",
    "    show -- Boolean indicating whether to show the resulting plot (default True)\n",
    "    save -- Boolean indicating whether to save the resulting plot (default False)'''\n",
    "    \n",
    "    # Create pandas dataframe with CCD coordinates\n",
    "    flares = getCCDCoords(t_i,t_f,getXrtFlareCat(t_i,t_f),flareType,pointings=pointings)\n",
    "    \n",
    "    # Create figure and name axes\n",
    "    g = sns.JointGrid(flares['x'],flares['y'],xlim=[0,2048],ylim=[0,2048],size=15)\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    ax1 = g.ax_marg_x\n",
    "    ax2 = g.ax_marg_y\n",
    "    ax_ccd = g.ax_joint\n",
    "    \n",
    "    # Create scatterplots and kdeplots\n",
    "    hit = flares[flares['XRT'] > 0]\n",
    "    missed = flares[flares['XRT'] == 0]\n",
    "    \n",
    "    scatterHit = ax_ccd.plot(hit['x'],hit['y'],'.',color='red')\n",
    "    scatterMissed = ax_ccd.plot(missed['x'],missed['y'],'.',color='grey')\n",
    "    \n",
    "    pointingFailures = missed.copy(deep=True)\n",
    "    for i,flare in pointingFailures.iterrows():\n",
    "        if flare['obs_note'] != 'no:pointing':\n",
    "            pointingFailures.drop(i,inplace=True)\n",
    "    \n",
    "    scatterPointing = ax_ccd.plot(pointingFailures['x'],pointingFailures['y'],'.',color='green',markersize=20)\n",
    "\n",
    "    \n",
    "    g.plot_marginals(sns.kdeplot,bw=30,color='yellow',shade=True)\n",
    "    \n",
    "    # Create titles and legend\n",
    "    title = flareType[0] + ' Flare CCD Locations'\n",
    "    fig.suptitle(title,size=50)\n",
    "\n",
    "    ax_ccd.text(.01,.01,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=25,\n",
    "            transform=ax_ccd.transAxes)\n",
    "    \n",
    "    ax_ccd.legend([scatterHit[0],scatterMissed[0]],['Imaged: ' + str(len(hit)),'Missed: ' + str(len(missed))],\n",
    "                  fontsize=20,markerscale=3)\n",
    "    \n",
    "    \n",
    "    # Format CCD axes features\n",
    "    ticks = [0,512,1024,1536,2048]\n",
    "    ax_ccd.set_xticks(ticks)\n",
    "    ax_ccd.set_yticks(ticks)\n",
    "    ax_ccd.set_xticklabels(ticks,size=15)\n",
    "    ax_ccd.set_yticklabels(ticks,size=15)\n",
    "    ax_ccd.set_xlabel('x',size=20)\n",
    "    ax_ccd.set_ylabel('y',size=20,rotation='horizontal')\n",
    "    ax_ccd.grid()\n",
    "    \n",
    "    # Add SOT and EIS FOVs\n",
    "    sot_coords = (1024+(36.6-328/2)/1.0286,1024+(23.1-164/2)/1.0286)\n",
    "    eis_coords = (1024+(36.6-17.1-360/2)/1.0286,1024+(23.1-2.4-510/2)/1.0286)\n",
    "    ax_ccd.add_patch(plt.Rectangle(sot_coords,328/1.0286,164/1.0286,fill=False,color='blue',zorder=2))\n",
    "    ax_ccd.add_patch(plt.Rectangle(eis_coords,360,510,fill=False,color='green',zorder=3))\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23558\n"
     ]
    }
   ],
   "source": [
    "def parse_events(events_file):\n",
    "    \"\"\"Parses an Hinode pointing file into a pandas-friendly form.\"\"\"\n",
    "    # Split into lines.\n",
    "    lines = split_and_purge(events_file, delim=\"\\n\")\n",
    "\n",
    "    # Throw away the first 8 lines. We do not need the info contained in them.\n",
    "    lines = lines[8:]\n",
    "\n",
    "    if len(lines) < 2:\n",
    "        return \"\"\n",
    "\n",
    "    # I manually set the column titles, as the formatting they come in is confusing, with titles spanning 2 lines\n",
    "    title_row = ['Repoint','Start Time', 'Tracking Curve','Offset-X','Offset-Y','Xpointing','Ypointing','Notes']\n",
    "\n",
    "    # Get the rows.\n",
    "    rows = []\n",
    "    for line in lines[:]:\n",
    "        if '/* End' not in line:\n",
    "            items = split_and_purge(line)\n",
    "        else:\n",
    "            break;\n",
    "\n",
    "        # Too few items.\n",
    "        if len(items) < 7:\n",
    "            continue\n",
    "\n",
    "        # The .join combines 2 items into one (for example making the day and time into one row)\n",
    "        rows.append([\" \".join(items[:2])] + [\" \".join(items[2:4])] + items[4:7] + items[8:10]+[\" \".join(items[10:])])\n",
    "\n",
    "    # Create csv.\n",
    "    strio = StringIO()\n",
    "    writer = csv.writer(strio)\n",
    "    writer.writerows([title_row] + rows)\n",
    "    return strio.getvalue()\n",
    "\n",
    "def parseTimelineInfo(page):\n",
    "    lines = split_and_purge(page, delim='\\n')\n",
    "    lines = lines[11:-5]\n",
    "    \n",
    "    output = []\n",
    "    for line in lines[:]:\n",
    "        if 'Plan' in line:\n",
    "            output.append(line.replace('>','<').split('<')[4])\n",
    "            \n",
    "    return output\n",
    "\n",
    "def getPointingFileName(page):\n",
    "    lines = split_and_purge(page, delim='\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        if 're-point_' in line:\n",
    "            return line.replace('re-point_','.txt').split('.txt')[1]\n",
    "        \n",
    "    return 'No pointing file'\n",
    "\n",
    "\n",
    "\n",
    "def getPointingFileInfo():\n",
    "    '''Return a pandas dataframe of all Hinode pointings'''\n",
    "    \n",
    "    timelines = urllib2.urlopen('https://xrt.cfa.harvard.edu/missionops/timelines/')\n",
    "    strio = StringIO(requests.get('https://xrt.cfa.harvard.edu/missionops/timelines/').content)\n",
    "    timelineFile = strio.read()\n",
    "    info = parseTimelineInfo(timelineFile)\n",
    "    \n",
    "    fileDates = []\n",
    "    \n",
    "    for date in info:\n",
    "        fileDates.append(datetime.datetime.strptime(date[:10],'%Y/%m/%d'))\n",
    "    \n",
    "    dfList = []\n",
    "    for date in fileDates:\n",
    "        url = 'http://xrt.cfa.harvard.edu/missionops/timelines/' + date.strftime('%Y%m%d') + '_Plan/' \n",
    "        webPage = urllib2.urlopen(url)\n",
    "        strio = StringIO(requests.get(url).content)\n",
    "        name = getPointingFileName(strio.read())\n",
    "        if name == 'No pointing file':\n",
    "            continue;\n",
    "        url = 'http://xrt.cfa.harvard.edu/missionops/timelines/' + date.strftime('%Y%m%d') + '_Plan/re-point_' + name + '.txt'\n",
    "        f = urllib2.urlopen(url)\n",
    "        strio = StringIO(requests.get(url).content)\n",
    "        dfList.append(pd.read_csv(StringIO(parse_events(strio.read()))))\n",
    "    \n",
    "    output = pd.concat(dfList)\n",
    "    \n",
    "    return output.reset_index(drop=True)\n",
    "\n",
    "print len(getPointingFileInfo())\n",
    "\n",
    "def isHOP79or130(time):\n",
    "    '''Return boolean. Argument is datetime object.'''\n",
    "    \n",
    "    t = time.strftime('%Y/%m/%d %H:%M:%S')\n",
    "    \n",
    "    concatFile = getPointingFileInfo(time)\n",
    "    \n",
    "    # If no pointing file is found, assume False\n",
    "    if concatFile is False:\n",
    "        return False\n",
    "\n",
    "    # Sequential search\n",
    "    for i,pointing in concatFile.iterrows():\n",
    "        if concatFile['Start Time'][i] < t and t < concatFile['Start Time'][i + 1]:\n",
    "            if 'HOP 79' in pointing['Notes'] or 'HOP 130' in pointing['Notes']:\n",
    "                return True\n",
    "            else:\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genObsNotePie(t_i,t_f,flareType=('All','B','Z'),imaged=True,save=False,show=True):\n",
    "    '''Create a pie chart showing the breakdown of obs_note reasons for the specified class range of flares\n",
    "    over the specified time period.\n",
    "    \n",
    "    Arguments:\n",
    "    t_i -- Initial time boundary (datetime object)\n",
    "    t_f -- Final time boundary (datetime object)\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    flareType -- Tuple indicating class range of flares that are of interest, e.g. ('C5 to X','C5','Z')\n",
    "                 (default ('All','B','Z'))\n",
    "    imaged -- Boolean indicating whether to include a slice for successfully imaged flares (default True)\n",
    "    save -- Boolean indicating whether to save the resulting figure (default False)\n",
    "    show -- Boolean indicating whether to show the resulting figure (default True)'''\n",
    "    \n",
    "    # Create pandas dataframe of relevant metadata\n",
    "    data = getXrtFlareCat(t_i,t_f)[['class','obs_note','t_start','x','y']]\n",
    "    \n",
    "    # Replace vague obs_notes with real reasons if in dict reasons1415\n",
    "    for i,flare in data.iterrows():\n",
    "        if flare['t_start'] in reasons1415.keys():\n",
    "            data.set_value(i,'obs_note',reasons1415[flare['t_start']])\n",
    "    \n",
    "    # Filter out imaged flares\n",
    "    missed = data[(data['obs_note'] < 'y') & (data['class'] > flareType[1]) & (data['class'] < flareType[2])]\n",
    "    \n",
    "    # Dictionary to both store number of occurences of each obs note and to provide consistent colorings\n",
    "    reasons = {'no:no_hk':[0,'blue'],'no:no_timeline':[0,'black'],'no:mode=1':[0,'lightsteelblue'],'no:no_obev':[0,'cyan'],\n",
    "               'no:pointing_out':[0,'darkgreen'],'no:cal_seq':[0,'yellow'],'no:no_sci':[0,'grey'],'no:orbital_event':[0,'magenta'],\n",
    "               'no:mode=7':[0,'darkgoldenrod'],'no:mode=3':[0,'darkred'],'no:mode=5':[0,'khaki'],'no:bakeout':[0,'orange'],\n",
    "               'no:seu':[0,'grey'],'no:mwm':[0,'violet'],'no:dam':[0,'lightblue'],'no:op_error':[0,'purple'],\n",
    "               'no:missing_data':[0,'black'],'no:pointing_in':[0,'lightgreen'],'no:HOP_70/130':[0,'darkgoldenrod']}\n",
    "\n",
    "    # Precompute concatFile for splitByPointings\n",
    "    concatFile = getPointingFileInfo(t_i,t_f)\n",
    "    \n",
    "    # Split pointing failures based on whether the flare occurred on the CCD FOV or not\n",
    "    sepPointings = splitByPointings(missed,['no:pointing'],pointings=concatFile)\n",
    "\n",
    "    for i,flare in sepPointings[0].iterrows():\n",
    "        missed.set_value(i,'obs_note','no:pointing_in')\n",
    "    for i,flare in sepPointings[1].iterrows():\n",
    "        missed.set_value(i,'obs_note','no:pointing_out')\n",
    "    \n",
    "    # Create frequency count for each obs_note, grouping some of them as requested\n",
    "    for note in missed['obs_note']:\n",
    "        if note == 'no:saa' or note == 'no:ngt' or note == 'no:xtw':\n",
    "            reasons['no:orbital_event'][0] += 1\n",
    "        elif note == 'no:calibration' or note == 'no:gband_only':\n",
    "            reasons['no:cal_seq'][0] += 1\n",
    "        elif note == 'no:fld_only' or note == 'no:no_obs_planned':\n",
    "            reasons['no:no_sci'][0] += 1\n",
    "        else:\n",
    "            reasons[note][0] += 1\n",
    "    \n",
    "    # Neatly organize data and labeling information for plot creation\n",
    "    sizes = [e[0] for e in reasons.values() if e[0]]\n",
    "    labels = [key[3:] + ': ' + str(e[0]) for key,e in zip(reasons.keys(),reasons.values()) if e[0]]\n",
    "    colors = [e[1] for e in reasons.values() if e[0]]\n",
    "    \n",
    "    if imaged:\n",
    "        sizes.append(len(data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])]) - len(missed))\n",
    "        labels.append('imaged: ' + str(sizes[-1]))\n",
    "        colors.append('red')\n",
    "    \n",
    "    # Create figure, axes, pie chart, and titles/labels\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    patches, texts, autotexts = ax.pie(sizes,labels=labels,colors=colors,autopct='%1.1f%%',textprops={'fontsize': 20})\n",
    "    for text in texts:\n",
    "        text.set_fontsize(20)\n",
    "    \n",
    "    ax.text(.01,.01,t_i.strftime('%Y-%m-%d %H:%M:%S') + ' to ' + t_f.strftime('%Y-%m-%d %H:%M:%S'),size=20,\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    title = 'obs_note Pie Chart for ' + flareType[0] + ' Flares'\n",
    "    fig.suptitle(title,size=40,x=.53,y=.95)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(t_i.strftime('%Y_%m_%d_') + title.replace(' ','_') + '.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary providing specific explanations for certain FLD failures. Created manually by Kathy Reeves.\n",
    "\n",
    "reasons1415 = {'2014/08/15 11:54': 'no:xtw','2014/10/20 13:58': 'yes:flare_imaged',\n",
    "               '2014/10/25 23:20': 'no:missing_data','2014/10/27 06:56': 'no:saa',\n",
    "               '2014/11/06 14:17': 'no:missing_data','2014/11/29 07:03': 'no:saa',\n",
    "               '2014/12/25 05:19': 'no:missing_data','2015/01/28 23:32': 'no:bakeout',\n",
    "               '2015/04/04 11:38': 'no:bakeout','2014/11/29 09:57': 'no:no_obs_planned',\n",
    "               '2014/12/01 05:11': 'no:saa','2014/12/02 07:58': 'no:missing_data',\n",
    "               '2014/12/04 11:32': 'no:missing_data','2015/04/06 05:46': 'no:bakeout',\n",
    "               '2015/04/06 18:35': 'no:no_obs_planned','2014/09/02 00:09': 'no:seu',\n",
    "               '2014/09/02 00:50': 'no:seu','2014/10/24 03:56': 'no:seu',\n",
    "               '2015/01/26 05:07': 'no:dam','2015/01/26 06:08': 'no:dam',\n",
    "               '2015/01/26 07:20': 'no:dam','2015/01/26 08:08': 'no:dam',\n",
    "               '2015/01/26 08:51': 'no:dam','2015/01/26 23:45': 'no:dam',\n",
    "               '2015/01/27 04:54': 'no:dam','2015/01/27 05:43': 'no:dam',\n",
    "               '2015/01/27 07:13': 'no:dam','2015/01/27 09:11': 'no:dam',\n",
    "               '2015/01/27 23:52': 'no:dam','2015/01/28 00:55': 'no:dam',\n",
    "               '2015/01/28 05:20': 'no:dam','2015/01/28 10:38': 'no:dam',\n",
    "               '2015/01/28 13:07': 'no:dam','2015/01/28 18:24': 'no:dam',\n",
    "               '2015/01/29 02:42': 'no:dam','2015/01/29 03:08': 'no:dam',\n",
    "               '2015/01/29 03:48': 'no:dam','2015/01/29 04:20': 'no:dam',\n",
    "               '2015/01/29 05:15': 'no:dam','2015/01/29 09:17': 'no:dam',\n",
    "               '2015/01/29 09:53': 'no:dam','2015/01/29 10:36': 'no:dam',\n",
    "               '2015/01/29 12:21': 'no:dam','2015/01/29 13:30': 'no:dam',\n",
    "               '2015/01/29 14:07': 'no:dam','2015/01/29 14:37': 'no:dam',\n",
    "               '2015/01/29 16:49': 'no:dam','2015/01/29 18:12': 'no:dam',\n",
    "               '2015/01/29 19:30': 'no:dam','2015/01/29 23:37': 'no:dam',\n",
    "               '2015/01/30 04:51': 'no:dam','2015/01/30 08:19': 'no:dam',\n",
    "               '2015/01/30 17:43': 'no:seu','2015/01/30 20:18': 'no:seu',\n",
    "               '2015/01/31 07:46': 'no:seu','2015/03/24 16:21': 'no:mwm',\n",
    "               '2015/03/25 01:34': 'no:mwm','2015/03/25 03:20': 'no:mwm',\n",
    "               '2015/03/25 04:36': 'no:mwm','2015/03/25 07:20': 'no:mwm',\n",
    "               '2015/03/25 08:23': 'no:mwm','2015/03/25 13:38': 'no:mwm',\n",
    "               '2015/03/25 16:30': 'no:mwm','2015/03/25 18:13': 'no:mwm',\n",
    "               '2015/03/26 00:06': 'no:mwm','2015/03/26 15:18': 'no:op_error',\n",
    "               '2015/03/26 19:05': 'no:op_error','2015/03/26 23:37': 'no:op_error',\n",
    "               '2015/03/27 06:30': 'no:op_error','2014/10/27 09:59': 'no:missing_data',\n",
    "               '2015/01/26 16:46': 'no:dam','2015/01/28 04:21': 'no:dam',\n",
    "               '2015/01/28 21:32': 'no:dam','2015/01/29 11:32': 'no:dam',\n",
    "               '2015/01/30 00:32': 'no:dam','2015/01/30 05:29': 'no:dam',\n",
    "               '2015/01/30 12:10': 'no:dam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitByPointings(data,filterList,pointings=None):\n",
    "    '''Break down misses in XRT Flare Catalog DataFrame by whether flare was in FOV of the CCD, even if XRT wasn't\n",
    "    observing. Return (inFOV,outFOV). Ignores flare with obs_notes other than those in filterList.\n",
    "    \n",
    "    Arguments:\n",
    "    data -- XRT Flare Catalog format DataFrame\n",
    "    \n",
    "    Keyword Arguments:\n",
    "    pointings -- Concatenated DataFrame of all Hinode pointings (default None)\n",
    "                 splitByPointings will generate DataFrame if not passed'''\n",
    "\n",
    "    if pointings is None:\n",
    "        t_i = datetime.datetime.strptime(data['t_start'][data.index[0]],'%Y/%m/%d %H:%M')\n",
    "        t_f = datetime.datetime.utcnow()\n",
    "        pointings = getPointingFileInfo(t_i,t_f)\n",
    "    \n",
    "    # Much faster to append to list and then create DataFrame than to use DataFrame operations\n",
    "    dataFilteredList = []\n",
    "    inFOVList = []\n",
    "    outFOVList = []\n",
    "    \n",
    "    # Filter out conditions where Hinode pointing may have intentionally been bad for the XRT FOV\n",
    "    for i,flare in data.iterrows():\n",
    "        if flare['obs_note'] in filterList:\n",
    "            dataFilteredList.append([i] + list(flare))\n",
    "    \n",
    "    dataFiltered = pd.DataFrame(dataFilteredList,columns=['index'] + list(data.columns))\n",
    "\n",
    "    # Iterate through data, finding the appropriate pointing and evaluating whether the flare was in XRT's FOV\n",
    "    for i,flare in dataFiltered.iterrows():\n",
    "        \n",
    "        j = len(pointings)/2\n",
    "        j_min = 0\n",
    "        j_max = len(pointings)\n",
    "    \n",
    "        a = pointings['Start Time'][j] < flare['t_start']\n",
    "        b = pointings['Start Time'][j + 1] > flare['t_start']\n",
    "    \n",
    "        # Binary search through 20,000+ pointings (1000x faster than sequential in this case)\n",
    "        while a is not b: # Simplest way to use logical xor in python\n",
    "            if not a:\n",
    "                j_max = j\n",
    "                j = (j_min + j_max)/2\n",
    "            else:\n",
    "                j_min = j\n",
    "                j = (j_min + j_max)/2\n",
    "        \n",
    "            a = pointings['Start Time'][j] < flare['t_start']\n",
    "            b = pointings['Start Time'][j + 1] > flare['t_start']\n",
    "\n",
    "        # Was the flare in the CCD FOV in both axes?\n",
    "        x = abs(float(pointings['Xpointing'][j][:-1]) - 40 - flare['x']) < 1024 * 1.0286\n",
    "        y = abs(pointings['Ypointing'][j] - 40 - flare['y']) < 1024 * 1.0286\n",
    "        \n",
    "        # Append flares to correct lists - many times faster than doing so with DataFrames\n",
    "        if x and y:\n",
    "            inFOVList.append([i] + list(flare))\n",
    "        else:\n",
    "            outFOVList.append([i] + list(flare))\n",
    "    \n",
    "    # Create DataFrames - this process maintains the original indices from the flare catalog dataframe\n",
    "    cols = pd.Series(['index']+list(data.columns))\n",
    "    inFOVList = [e[1:] for e in inFOVList]\n",
    "    outFOVList = [e[1:] for e in outFOVList]\n",
    "    \n",
    "    inFOV = pd.DataFrame(inFOVList,columns=cols)\n",
    "    outFOV = pd.DataFrame(outFOVList,columns=cols)\n",
    "    inFOV = inFOV.set_index('index')\n",
    "    outFOV = outFOV.set_index('index')\n",
    "\n",
    "    return (inFOV,outFOV);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate large DataFrame of Hinode pointings. Takes ~60s to run.\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "pointings = getPointingFileInfo()\n",
    "\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Master Cell -- use this cell to call all desired functions\n",
    "\n",
    "\n",
    "# Set time period for plots\n",
    "t_f = datetime.datetime.utcnow()-datetime.timedelta(days=0)\n",
    "t_i = t_f - datetime.timedelta(days=365)\n",
    "\n",
    "\n",
    "# Generate pandas DataFrame of XRT Flare Catalog\n",
    "data = getXrtFlareCat(t_i,t_f)\n",
    "\n",
    "types = [('All','B','Z'),('C5 to X','C5','Z')]#,('B','B','C'),('C','C','M'),('M','M','X'),('X','X','Z')]\n",
    "\n",
    "# Loop iterates over the list types creating plots for each type. Not always desired, but can save a lot of time.\n",
    "# Remember to use the save (default False) and show (default True) keyword arguments as desired\n",
    "for flareType in types:\n",
    "    #Generate and save plots\n",
    "    try:\n",
    "        #genDistPlot(t_i,t_f,flareType,data=data,bw=125)\n",
    "        #genProbPlot(t_i,t_f,flareType,data=data,bw=125,save=True)\n",
    "        #genHistogram(t_i,t_f,flareType,data=data)\n",
    "        #genFlareResPlot(t_i,t_f,flareType,data=data,bw=125)\n",
    "        #genObsNoteDistPlot(t_i,t_f,flareType,bw=150,save=True)\n",
    "        #genObsNotePie(t_i,t_f,flareType)\n",
    "        #genObsNotesClassPlot(t_i,t_f,flareType)\n",
    "        continue;\n",
    "    except ValueError:\n",
    "        print 'ValueError'\n",
    "    continue;\n",
    "    \n",
    "#genFRPercentPlot(t_i,t_f)\n",
    "#genFRValuePlot(t_i,t_f)\n",
    "#genObsNotesPlot(t_i,t_f)\n",
    "#genObsNotesClassPlot(t_i,t_f,('C5 to X','C5','Z'))\n",
    "#genObsNotesClassPlot(t_i,t_f,('C5 to X','C5','Z'))\n",
    "#genObsNoteDistPlot(t_i,t_f,('C5 to X','C5','Z'),bw=150)\n",
    "\n",
    "t_f = datetime.datetime(2013,7,1)\n",
    "t_i = datetime.datetime(2013,1,1)\n",
    "#genObsNotePie(t_i,t_f,('C5 to X','C5','X'))\n",
    "\n",
    "t_f = datetime.datetime(2014,1,1)\n",
    "t_i = datetime.datetime(2013,7,1)\n",
    "#genObsNotePie(t_i,t_f,('C5 to X','C5','X'))\n",
    "\n",
    "t_f = datetime.datetime.utcnow()-datetime.timedelta(days=365*0)\n",
    "t_i = t_f - datetime.timedelta(days=365*1)\n",
    "genCCDPlot(t_i,t_f,('C5 to X','C5','Z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate large DataFrame of pointings for STEREO and Focus Mode analysis cells. Takes ~60s to run.\n",
    "# Make sure t_i to t_f covers the time range that is being investigated.\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "t_i = datetime.datetime(2009,1,1)\n",
    "t_f = datetime.datetime.utcnow()\n",
    "pointings = getPointingFileInfo(t_i,t_f)\n",
    "\n",
    "print time.time()-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# STEREO Mission analysis cell\n",
    "\n",
    "t_f = datetime.datetime.utcnow()\n",
    "t_i = datetime.datetime(2009,1,1)\n",
    "\n",
    "flareType = ('C5 to X','C5','Z')\n",
    "z = 2\n",
    "\n",
    "data = getXrtFlareCat(t_i,t_f)\n",
    "\n",
    "data = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])]\n",
    "\n",
    "# Create DataFrames for flares that occurred in and out of the CCD FOV, respectively\n",
    "filterList = ['no:pointing','no:bakeout','no:fld_only','no:no_obs_planned','no:saa','no:xtw','no:ngt',\n",
    "              'yes:no_response','yes:with_response']\n",
    "inFOV, outFOV = splitByPointings(data,pointings=pointings,filterList=filterList)\n",
    "\n",
    "# STEREO: ~45 degrees to ~135 degrees\n",
    "t_f = datetime.datetime(2013,3,1)\n",
    "t_i = datetime.datetime(2009,2,1)\n",
    "\n",
    "# non-STEREO\n",
    "t_f2 = datetime.datetime.utcnow()\n",
    "t_i2 = datetime.datetime(2013,3,1)\n",
    "\n",
    "# Create and name figure and axes\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "leg = []\n",
    "labels = []\n",
    "\n",
    "# Create plots\n",
    "for period in [(t_i,t_f,'STEREO',[-755,-255,245,745],'red'),(t_i2,t_f2,'non-STEREO',[-745,-245,255,755],'blue')]:\n",
    "    \n",
    "    regionDict = {'All': None, 'E': None, 'CE': None, 'CW': None, 'W': None}\n",
    "    flares = 0\n",
    "    \n",
    "    # Analyze performance by region\n",
    "    for region in [(-1200,1200,'All'),(-1200,-500,'E'),(-500,0,'CE'),(0,500,'CW'),(500,1200,'W')]:\n",
    "        \n",
    "        # Filter DataFrames by region and by time period\n",
    "        subsetIn = inFOV[((inFOV['x'] > region[0]) & (inFOV['x'] < region[1]) & \n",
    "                          (inFOV['t_start'] > period[0].strftime('%Y/%m/%d %H:%M')) & \n",
    "                          (inFOV['t_start'] < period[1].strftime('%Y/%m/%d %H:%M')))]\n",
    "        \n",
    "        subsetOut = outFOV[((outFOV['x'] > region[0]) & (outFOV['x'] < region[1]) & \n",
    "                          (outFOV['t_start'] > period[0].strftime('%Y/%m/%d %H:%M')) & \n",
    "                          (outFOV['t_start'] < period[1].strftime('%Y/%m/%d %H:%M')))]\n",
    "        \n",
    "        # Calculate and store statistics\n",
    "        right = len(subsetIn)\n",
    "        wrong = len(subsetOut)\n",
    "        total = float(right) + float(wrong)\n",
    "        \n",
    "        p = right / total\n",
    "        error = z*(p*(1-p)/total)**0.5 \n",
    "        \n",
    "        regionDict[region[2]] = (p,error)\n",
    "        flares += total\n",
    "    \n",
    "    # Neatly create and store plotting arguments\n",
    "    x = period[3]\n",
    "    y = [e[0] for e in [regionDict[key] for key in ['E','CE','CW','W']]]\n",
    "    err = [e[1] for e in [regionDict[key] for key in ['E','CE','CW','W']]]\n",
    "    color = period[4]\n",
    "    \n",
    "    # Create errorbars and plot\n",
    "    ax.errorbar(x,y,yerr=err,capthick=2,capsize=10,ecolor=color)\n",
    "    plot = ax.plot(x,y,'-o',color=color)\n",
    "    \n",
    "    # Append to legend and labels\n",
    "    leg.append(plot[0])\n",
    "    labels.append(period[2] + ': ' + str(int(flares/2)))\n",
    "\n",
    "# Create legend, text, and title\n",
    "ax.legend(leg,labels,fontsize=25,markerscale=2,loc=4)\n",
    "ax.text(0.025,0.033,str(z) + '-sigma\\n' + flareType[0] + ' Flares',size=25,\n",
    "        transform=ax.transAxes,linespacing = 1.7)\n",
    "fig.suptitle('Pointing Success vs. Longitudinal Location', size = 40)\n",
    "\n",
    "# Customize axes\n",
    "ax.axis([-1000,1000,0,1])\n",
    "ax.set_yticks([.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_yticklabels([.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0],size=15)\n",
    "ax.set_xticklabels([-1000,-500,0,500,1000],size=15)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Focus Mode analysis cell\n",
    "\n",
    "t_f = datetime.datetime.utcnow()\n",
    "t_i = datetime.datetime(2014,1,1)\n",
    "\n",
    "flareType = ('C5 to X','C5','Z')\n",
    "z = 2\n",
    "\n",
    "# Create and name figure and axes\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "leg = []\n",
    "labels = []\n",
    "\n",
    "# Create plots\n",
    "for period in [('Normal Focus Mode',[-755,-255,245,745],'red',True,False),\n",
    "               ('Normal Mode',[-745,-245,255,755],'blue',False,True)]:\n",
    "    print period[0]\n",
    "    print '\\n\\n'\n",
    "    \n",
    "    data = getXrtFlareCat(t_i,t_f,fmn=period[3],nm=period[4])\n",
    "\n",
    "    data = data[(data['class'] > flareType[1]) & (data['class'] < flareType[2])]\n",
    "    \n",
    "    print len(data)\n",
    "    \n",
    "    # Create DataFrames for flares in and out of the CCD FOV, respectively\n",
    "    filterList = ['no:pointing','no:bakeout','no:fld_only','no:no_obs_planned','no:saa','no:xtw','no:ngt',\n",
    "              'yes:no_response','yes:with_response']\n",
    "    inFOV, outFOV = splitByPointings(data,pointings=pointings,filterList=filterList)\n",
    "\n",
    "    regionDict = {'All': None, 'E': None, 'CE': None, 'CW': None, 'W': None}\n",
    "    \n",
    "    flares = 0\n",
    "    \n",
    "    for region in [(-1200,1200,'All'),(-1200,-500,'E'),(-500,0,'CE'),(0,500,'CW'),(500,1200,'W')]:\n",
    "        print region\n",
    "        \n",
    "        # Filter DataFrames by region\n",
    "        subsetIn = inFOV[(inFOV['x'] > region[0]) & (inFOV['x'] < region[1])]\n",
    "        subsetOut = outFOV[(outFOV['x'] > region[0]) & (outFOV['x'] < region[1])]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        right = len(subsetIn)\n",
    "        wrong = len(subsetOut)\n",
    "        total = float(right) + float(wrong)\n",
    "        \n",
    "        p = right / total\n",
    "        error = z*(p*(1-p)/total)**0.5 \n",
    "        \n",
    "        regionDict[region[2]] = (p,error)\n",
    "        flares += total\n",
    "        print right\n",
    "        print total\n",
    "        print p\n",
    "        print ''\n",
    "    \n",
    "    # Neatly create and store plotting arguments\n",
    "    x = period[1]\n",
    "    y = [e[0] for e in [regionDict[key] for key in ['E','CE','CW','W']]]\n",
    "    err = [e[1] for e in [regionDict[key] for key in ['E','CE','CW','W']]]\n",
    "    color = period[2]\n",
    "    \n",
    "    # Create errorbars and plot \n",
    "    ax.errorbar(x,y,yerr=err,capthick=2,capsize=10,ecolor=color)\n",
    "    plot = ax.plot(x,y,'-o',color=color)\n",
    "    \n",
    "    # Append information to legend and labels\n",
    "    leg.append(plot[0])\n",
    "    labels.append(period[0] + ': ' + str(int(flares/2)))\n",
    "\n",
    "# Create legend, text, and title\n",
    "ax.legend(leg,labels,fontsize=25,markerscale=2,loc=4)\n",
    "ax.text(0.025,0.033,str(z) + '-sigma\\n' + flareType[0] + ' Flares',size=25,\n",
    "        transform=ax.transAxes,linespacing = 1.7)\n",
    "fig.suptitle('Pointing Success vs. Longitudinal Location', size = 40)\n",
    "\n",
    "# Customize axes\n",
    "ax.axis([-1000,1000,0,1])\n",
    "ax.set_yticks([.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0])\n",
    "ax.set_yticklabels([.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0],size=15)\n",
    "ax.set_xticklabels([-1000,-500,0,500,1000],size=15)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Movie generation cell #1\n",
    "\n",
    "t_f = datetime.datetime.utcnow()\n",
    "t_i = datetime.datetime(2006,10,19)\n",
    "\n",
    "data = getXrtFlareCat(t_i,t_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Movie generation cell #2\n",
    "#\n",
    "# A memory leak exists in genDistPlot if save == True as of 2015-08-25 -- Only create 150-250 frames at a time\n",
    "\n",
    "for day in range(2689,2715): # Use the range to specify which frames to generate\n",
    "    \n",
    "    start = datetime.datetime(2006,10,20) + datetime.timedelta(days=day)\n",
    "    end = start + datetime.timedelta(days=182)\n",
    "    \n",
    "    # getXrtFlareCat is only called once (previous cell) to save time/resources. Date filtering is therefore\n",
    "    # necessary on each iteration\n",
    "    dataFiltered = data[((data['t_start'] > start.strftime('%Y/%m/%d %H:%M')) & \n",
    "                         (data['t_start'] < end.strftime('%Y/%m/%d %H:%M')))]\n",
    "\n",
    "    #Generate and save plot\n",
    "    try:\n",
    "        genDistPlot(start,end,('Solar','B','Z'),scale=True,show=False,save=True,data=dataFiltered)\n",
    "        gc.collect()\n",
    "    except ZeroDivisionError:\n",
    "        print 'skipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
